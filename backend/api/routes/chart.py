# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Chart Data Endpoints (Multi-Timeframe Support)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ğŸ“Œ ì—­í• :
#     Intraday ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ API
#
# ğŸ“Œ ì—”ë“œí¬ì¸íŠ¸:
#     GET /chart/intraday/{ticker} - Intraday ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
from datetime import datetime, timedelta

from fastapi import APIRouter, HTTPException
from loguru import logger

from .common import get_timestamp


router = APIRouter()


@router.get("/chart/intraday/{ticker}", summary="Intraday ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ")
async def get_intraday_chart(
    ticker: str,
    timeframe: int = 5,  # 1, 5, 15, 60 (ë¶„ ë‹¨ìœ„)
    days: int = 2,  # ì¡°íšŒ ì¼ìˆ˜ (1-10)
):
    """
    íŠ¹ì • ì¢…ëª©ì˜ Intraday ì°¨íŠ¸ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    ğŸ“Œ íƒ€ì„í”„ë ˆì„:
        - 1: 1ë¶„ë´‰
        - 5: 5ë¶„ë´‰
        - 15: 15ë¶„ë´‰
        - 60: 1ì‹œê°„ë´‰

    ğŸ“Œ ë°˜í™˜ê°’:
        - candles: OHLCV ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        - ticker: ì¢…ëª© ì‹¬ë³¼
        - timeframe: íƒ€ì„í”„ë ˆì„ (ë¶„)
        - count: ë°ì´í„° ê°œìˆ˜

    Example:
        GET /api/chart/intraday/AAPL?timeframe=5&days=2
    """
    from backend.data.massive_client import MassiveClient

    # API Key í™•ì¸
    api_key = os.getenv("MASSIVE_API_KEY", "")
    if not api_key:
        raise HTTPException(status_code=500, detail="MASSIVE_API_KEY not configured")

    # íŒŒë¼ë¯¸í„° ê²€ì¦
    if timeframe not in [1, 5, 15, 60]:
        raise HTTPException(
            status_code=400, detail="Invalid timeframe. Use 1, 5, 15, or 60"
        )
    if days < 1 or days > 10:
        raise HTTPException(status_code=400, detail="Days must be between 1 and 10")

    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    to_date = datetime.now().strftime("%Y-%m-%d")
    from_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

    logger.info(
        f"ğŸ“Š Intraday ì°¨íŠ¸ ì¡°íšŒ: {ticker} {timeframe}m ({from_date} ~ {to_date})"
    )

    try:
        async with MassiveClient(api_key) as client:
            bars = await client.fetch_intraday_bars(
                ticker=ticker.upper(),
                multiplier=timeframe,
                from_date=from_date,
                to_date=to_date,
                limit=5000,
            )

        if not bars:
            return {
                "status": "no_data",
                "ticker": ticker.upper(),
                "timeframe": timeframe,
                "count": 0,
                "candles": [],
                "timestamp": get_timestamp(),
            }

        # ì°¨íŠ¸ ìœ„ì ¯ í¬ë§·ìœ¼ë¡œ ë³€í™˜ (timestamp -> time)
        candles = []
        for bar in bars:
            candles.append(
                {
                    "time": bar["timestamp"]
                    // 1000,  # ms -> seconds (TradingView í¬ë§·)
                    "open": bar["open"],
                    "high": bar["high"],
                    "low": bar["low"],
                    "close": bar["close"],
                    "volume": bar["volume"],
                }
            )

        return {
            "status": "success",
            "ticker": ticker.upper(),
            "timeframe": timeframe,
            "count": len(candles),
            "candles": candles,
            "timestamp": get_timestamp(),
        }

    except Exception as e:
        logger.error(f"Intraday ì°¨íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GET /chart/bars - íˆìŠ¤í† ë¦¬ì»¬ ë°” ì¡°íšŒ (L2 â†’ L3 ìºì‹œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ğŸ“Œ ì—­í• :
#     ì°¨íŠ¸ Pan/Zoom ì‹œ ì¶”ê°€ íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     L2 (SQLite) ë¨¼ì € ì¡°íšŒ, Miss ì‹œ L3 (Massive API) í˜¸ì¶œ í›„ ìºì‹±.
#
# ğŸ“Œ ì´ë™ ë°°ê²½:
#     ì›ë˜ frontend/gui/dashboard.pyì˜ _fetch_historical_bars()ì— ìˆë˜ ë¡œì§.
#     Frontendê°€ DB/API ì§ì ‘ ì ‘ê·¼í•˜ëŠ” ê²ƒì€ ì•„í‚¤í…ì²˜ ìœ„ë°˜ì´ë¯€ë¡œ Backendë¡œ ì´ë™.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@router.get("/chart/bars", summary="íˆìŠ¤í† ë¦¬ì»¬ ë°” ì¡°íšŒ (Parquet ìºì‹œ)")
async def get_historical_bars(
    ticker: str,
    timeframe: str = "5m",  # 1m, 5m, 15m, 1h
    limit: int = 100,  # ê°€ì ¸ì˜¬ ë°” ê°œìˆ˜
    before: int = None,  # ì´ íƒ€ì„ìŠ¤íƒ¬í”„(ms) ì´ì „ ë°ì´í„° ì¡°íšŒ
):
    """
    íˆìŠ¤í† ë¦¬ì»¬ ë°” ë°ì´í„° ì¡°íšŒ (Parquet â†’ API ìºì‹œ)

    ğŸ“Œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
        ì°¨íŠ¸ë¥¼ ì™¼ìª½(ê³¼ê±°)ìœ¼ë¡œ ìŠ¤í¬ë¡¤í•  ë•Œ ì¶”ê°€ ë°ì´í„° ë¡œë“œ

    ğŸ“Œ [11-002] ìºì‹œ ì „ëµ (Parquet ì „í™˜):
        1. DataRepositoryì—ì„œ Parquet ì¡°íšŒ (auto_fill=True)
        2. ëˆ„ë½ ì‹œ â†’ Massive API ìë™ í˜¸ì¶œ â†’ Parquet ì €ì¥

    Example:
        GET /api/chart/bars?ticker=AAPL&timeframe=5m&limit=100&before=1704067200000
    """
    from backend.container import container

    # =========================================================================
    # íŒŒë¼ë¯¸í„° íŒŒì‹±
    # =========================================================================
    ticker = ticker.upper()

    # íƒ€ì„í”„ë ˆì„ â†’ ParquetManager í˜•ì‹ ë³€í™˜
    tf_map = {"1m": "1m", "5m": "5m", "15m": "15m", "1h": "1h"}
    parquet_tf = tf_map.get(timeframe.lower(), "5m")

    # ê¸°ì¤€ ì‹œê°„ (beforeê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„)
    if before:
        ref_time = datetime.fromtimestamp(before / 1000)
    else:
        ref_time = datetime.now()

    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚° (í•˜ë£¨ ë°” ê°œìˆ˜ ì¶”ì •ìœ¼ë¡œ í•„ìš” ì¼ìˆ˜ ì‚°ì¶œ)
    tf_to_min = {"1m": 1, "5m": 5, "15m": 15, "1h": 60}
    multiplier = tf_to_min.get(parquet_tf, 5)
    bars_per_day = {1: 390, 5: 78, 15: 26, 60: 7}.get(multiplier, 78)
    days_back = max(5, limit // bars_per_day + 2)

    from_date = (ref_time - timedelta(days=days_back)).strftime("%Y-%m-%d")
    to_date = (ref_time - timedelta(days=1)).strftime("%Y-%m-%d")

    logger.info(f"ğŸ“Š Historical bars: {ticker} {timeframe} ({from_date} ~ {to_date})")

    try:
        # =====================================================================
        # [11-002] DataRepositoryë¥¼ í†µí•œ Parquet ì¡°íšŒ
        # ELI5: DataRepositoryê°€ ì•Œì•„ì„œ Parquetì—ì„œ ì½ê³ , ì—†ìœ¼ë©´ API í˜¸ì¶œí•´ì„œ ì €ì¥
        # =====================================================================
        repo = container.data_repository()

        # DataRepositoryì˜ get_intraday_bars ì‚¬ìš© (auto_fill=True ê¸°ë³¸ê°’)
        df = await repo.get_intraday_bars(
            ticker=ticker,
            timeframe=parquet_tf,
            days=days_back,
        )

        if df.empty:
            return {
                "status": "no_data",
                "ticker": ticker,
                "timeframe": timeframe,
                "count": 0,
                "candles": [],
                "timestamp": get_timestamp(),
            }

        # DataFrame â†’ candles ë¦¬ìŠ¤íŠ¸ ë³€í™˜
        candles = []
        for _, row in df.iterrows():
            ts = row.get("timestamp", 0)
            if ts > 1e12:  # ms â†’ seconds
                ts = ts // 1000

            candles.append(
                {
                    "time": ts,
                    "open": row["open"],
                    "high": row["high"],
                    "low": row["low"],
                    "close": row["close"],
                    "volume": row.get("volume", 0),
                }
            )

        # limit ê°œìˆ˜ë¡œ ì œí•œ
        if len(candles) > limit:
            candles = candles[-limit:]

        logger.info(f"ğŸ“¥ DataRepository: {len(candles)} bars from Parquet")

        return {
            "status": "success",
            "source": "parquet_cache",
            "ticker": ticker,
            "timeframe": timeframe,
            "count": len(candles),
            "candles": candles,
            "timestamp": get_timestamp(),
        }

    except Exception as e:
        logger.error(f"Historical bars ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _format_candles(bars: list) -> list:
    """
    ë°” ë°ì´í„°ë¥¼ ì°¨íŠ¸ ìœ„ì ¯ í¬ë§·ìœ¼ë¡œ ë³€í™˜

    ğŸ“Œ ë³€í™˜:
        - timestamp (ms) â†’ time (seconds) for TradingView í¬ë§·
    """
    candles = []
    for bar in bars:
        ts = bar.get("timestamp", bar.get("time", 0))
        if ts > 1e12:  # ms â†’ seconds
            ts = ts // 1000

        candles.append(
            {
                "time": ts,
                "open": bar["open"],
                "high": bar["high"],
                "low": bar["low"],
                "close": bar["close"],
                "volume": bar.get("volume", 0),
            }
        )
    return candles
