# ============================================================================
# Market Data Database - SQLAlchemy 2.0 Async
# ============================================================================
# ğŸ“Œ ì´ íŒŒì¼ì˜ ì—­í• :
#   - ì‹œì¥ ë°ì´í„°ë¥¼ SQLiteì— ì €ì¥í•˜ê³  ì¡°íšŒí•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ë ˆì´ì–´
#   - ORM ëª¨ë¸ ì •ì˜ (DailyBar, Ticker)
#   - Bulk Insert/Upsert ìµœì í™”
#
# ğŸ—„ï¸ í…Œì´ë¸” êµ¬ì¡°:
#   - daily_bars: ì¼ë³„ OHLCV ì‹œê³„ì—´ ë°ì´í„° (Composite PK: ticker + date)
#   - tickers: ì¢…ëª© ë©”íƒ€ì •ë³´ + í€ë”ë©˜í„¸ (ì‹œê°€ì´ì•¡, Float ë“±)
#
# âš™ï¸ ìµœì í™”:
#   - WAL Mode (Write-Ahead Logging) í™œì„±í™”ë¡œ ë™ì‹œì„± í–¥ìƒ
#   - Bulk Upsertë¡œ ëŒ€ëŸ‰ ë°ì´í„° ë¹ ë¥´ê²Œ ì²˜ë¦¬
#
# ğŸ“– ì‚¬ìš© ì˜ˆì‹œ:
#   >>> db = MarketDB("data/market_data.db")
#   >>> await db.initialize()
#   >>> await db.upsert_bulk([bar1, bar2, bar3])
# ============================================================================

import os
from datetime import datetime
from typing import Optional, Sequence

from sqlalchemy import String, Float, Integer, Text, select, text
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy.dialects.sqlite import insert as sqlite_insert

from loguru import logger


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ORM Base í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Base(DeclarativeBase):
    """
    SQLAlchemy ORMì˜ ê¸°ë³¸ í´ë˜ìŠ¤
    
    ëª¨ë“  ORM ëª¨ë¸ì€ ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ìŠµë‹ˆë‹¤.
    SQLAlchemy 2.0 ìŠ¤íƒ€ì¼ì˜ DeclarativeBaseë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DailyBar ëª¨ë¸ - ì¼ë´‰ ì‹œê³„ì—´ ë°ì´í„°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DailyBar(Base):
    """
    ì¼ë³„ OHLCV ë°ì´í„° ëª¨ë¸
    
    Polygon.ioì˜ Grouped Daily APIì—ì„œ ë°›ì•„ì˜¨ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    ê° ì¢…ëª©(ticker)ê³¼ ë‚ ì§œ(date)ì˜ ì¡°í•©ì´ Primary Keyì…ë‹ˆë‹¤.
    
    Attributes:
        ticker: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: "AAPL", "MSFT")
        date: ê±°ë˜ì¼ (YYYY-MM-DD í˜•ì‹)
        open: ì‹œê°€ (Opening Price)
        high: ê³ ê°€ (High Price)
        low: ì €ê°€ (Low Price)
        close: ì¢…ê°€ (Closing Price)
        volume: ê±°ë˜ëŸ‰ (ì²´ê²° ìˆ˜ëŸ‰)
        vwap: ê±°ë˜ëŸ‰ ê°€ì¤‘ í‰ê· ê°€ (Volume Weighted Average Price)
        transactions: ì²´ê²° ê±´ìˆ˜ (ê±°ë˜ íšŸìˆ˜)
    
    Example:
        >>> bar = DailyBar(
        ...     ticker="AAPL",
        ...     date="2024-12-17",
        ...     open=150.0,
        ...     high=152.5,
        ...     low=149.0,
        ...     close=151.0,
        ...     volume=50000000,
        ...     vwap=150.8,
        ...     transactions=100000
        ... )
    """
    __tablename__ = "daily_bars"
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Primary Key (Composite: ticker + date)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ticker: Mapped[str] = mapped_column(String(20), primary_key=True)
    date: Mapped[str] = mapped_column(String(10), primary_key=True)  # YYYY-MM-DD
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # OHLCV ë°ì´í„°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    open: Mapped[float] = mapped_column(Float, nullable=False)
    high: Mapped[float] = mapped_column(Float, nullable=False)
    low: Mapped[float] = mapped_column(Float, nullable=False)
    close: Mapped[float] = mapped_column(Float, nullable=False)
    volume: Mapped[int] = mapped_column(Integer, nullable=False)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vwap: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    transactions: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
    
    def __repr__(self) -> str:
        return f"<DailyBar({self.ticker} @ {self.date}: O={self.open} H={self.high} L={self.low} C={self.close} V={self.volume})>"
    
    def to_dict(self) -> dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (API ì‘ë‹µìš©)"""
        return {
            "ticker": self.ticker,
            "date": self.date,
            "open": self.open,
            "high": self.high,
            "low": self.low,
            "close": self.close,
            "volume": self.volume,
            "vwap": self.vwap,
            "transactions": self.transactions,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ticker ëª¨ë¸ - ì¢…ëª© ë©”íƒ€ì •ë³´ + í€ë”ë©˜í„¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Ticker(Base):
    """
    ì¢…ëª© ë©”íƒ€ì •ë³´ ë° í€ë”ë©˜í„¸ ë°ì´í„° ëª¨ë¸
    
    Universe Filterì— ì‚¬ìš©ë˜ëŠ” ì‹œê°€ì´ì•¡, Float ë“±ì˜ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    Polygon.ioì˜ Ticker Details APIì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Attributes:
        ticker: ì¢…ëª© ì‹¬ë³¼ (Primary Key)
        name: ì¢…ëª©ëª… (íšŒì‚¬ëª…)
        market_cap: ì‹œê°€ì´ì•¡ (USD)
        outstanding_shares: ì´ ë°œí–‰ ì£¼ì‹ ìˆ˜
        float_shares: ìœ í†µ ì£¼ì‹ ìˆ˜ (ê±°ë˜ ê°€ëŠ¥í•œ ì£¼ì‹)
        primary_exchange: ì£¼ ê±°ë˜ì†Œ (NYSE, NASDAQ ë“±)
        last_updated: ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ë‚ ì§œ
    
    Note:
        - market_capê³¼ float_sharesëŠ” Universe Filterì—ì„œ ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        - masterplan.md 3.1ì ˆì˜ í•„í„° ì¡°ê±´ ì°¸ê³ :
          * Market Cap: $50M ~ $300M (ë§ˆì´í¬ë¡œìº¡)
          * Float: < 15M shares (Low Float)
    """
    __tablename__ = "tickers"
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Primary Key
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ticker: Mapped[str] = mapped_column(String(20), primary_key=True)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ë³¸ ì •ë³´
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    name: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
    primary_exchange: Mapped[Optional[str]] = mapped_column(String(20), nullable=True)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í€ë”ë©˜í„¸ (Universe Filterìš©)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    market_cap: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    outstanding_shares: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    float_shares: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë©”íƒ€ë°ì´í„°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    last_updated: Mapped[Optional[str]] = mapped_column(String(10), nullable=True)
    
    def __repr__(self) -> str:
        return f"<Ticker({self.ticker}: {self.name}, MCap=${self.market_cap:,.0f})>" if self.market_cap else f"<Ticker({self.ticker})>"
    
    def to_dict(self) -> dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (API ì‘ë‹µìš©)"""
        return {
            "ticker": self.ticker,
            "name": self.name,
            "market_cap": self.market_cap,
            "outstanding_shares": self.outstanding_shares,
            "float_shares": self.float_shares,
            "primary_exchange": self.primary_exchange,
            "last_updated": self.last_updated,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MarketDB í´ë˜ìŠ¤ - ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MarketDB:
    """
    ì‹œì¥ ë°ì´í„° ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
    
    SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•œ CRUD ì‘ì—…ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    WAL ëª¨ë“œë¡œ ë™ì‹œì„±ì„ ìµœì í™”í•˜ê³ , Bulk Upsertë¡œ ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Attributes:
        db_path: SQLite íŒŒì¼ ê²½ë¡œ
        engine: SQLAlchemy Async Engine
        session_factory: Async Session íŒ©í† ë¦¬
    
    Example:
        >>> db = MarketDB("data/market_data.db")
        >>> await db.initialize()  # í…Œì´ë¸” ìƒì„± + WAL ëª¨ë“œ
        >>> 
        >>> # ë°ì´í„° ì¡°íšŒ
        >>> bars = await db.get_daily_bars("AAPL", days=20)
        >>> 
        >>> # ë°ì´í„° ì‚½ì…/ì—…ë°ì´íŠ¸
        >>> await db.upsert_bulk([bar1, bar2, bar3])
    """
    
    def __init__(self, db_path: str = "data/market_data.db"):
        """
        MarketDB ì´ˆê¸°í™”
        
        Args:
            db_path: SQLite íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: "data/market_data.db")
        
        Note:
            - íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±ë©ë‹ˆë‹¤.
            - ê²½ë¡œì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
        """
        self.db_path = db_path
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        db_dir = os.path.dirname(db_path)
        if db_dir and not os.path.exists(db_dir):
            os.makedirs(db_dir, exist_ok=True)
            logger.info(f"ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±: {db_dir}")
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # SQLAlchemy Async Engine ìƒì„±
        # - aiosqlite ë“œë¼ì´ë²„ ì‚¬ìš© (ë¹„ë™ê¸° SQLite)
        # - echo=False: SQL ì¿¼ë¦¬ ë¡œê¹… ë¹„í™œì„±í™” (ì„±ëŠ¥)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.engine = create_async_engine(
            f"sqlite+aiosqlite:///{db_path}",
            echo=False,  # SQL ì¿¼ë¦¬ ë¡œê¹… (ë””ë²„ê·¸ ì‹œ True)
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Session Factory ìƒì„±
        # - expire_on_commit=False: ì»¤ë°‹ í›„ì—ë„ ê°ì²´ ì ‘ê·¼ ê°€ëŠ¥
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.session_factory = async_sessionmaker(
            self.engine,
            class_=AsyncSession,
            expire_on_commit=False,
        )
        
        logger.debug(f"ğŸ—„ï¸ MarketDB ì´ˆê¸°í™”: {db_path}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì´ˆê¸°í™” ë©”ì„œë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def initialize(self) -> None:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        
        í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±í•˜ê³ , WAL ëª¨ë“œë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.
        
        WAL (Write-Ahead Logging) ëª¨ë“œ:
            - ì½ê¸°ì™€ ì“°ê¸°ë¥¼ ë™ì‹œì— í•  ìˆ˜ ìˆì–´ì„œ ë™ì‹œì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.
            - ì“°ê¸° ì‘ì—…ì´ ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤ (íŠ¹íˆ Bulk Insert).
            - ì „ì› ì¥ì•  ì‹œì—ë„ ë°ì´í„° ë¬´ê²°ì„±ì´ ë³´ì¥ë©ë‹ˆë‹¤.
        """
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        async with self.engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # WAL ëª¨ë“œ í™œì„±í™”
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        async with self.session_factory() as session:
            await session.execute(text("PRAGMA journal_mode=WAL"))
            await session.execute(text("PRAGMA synchronous=NORMAL"))  # ì„±ëŠ¥ í–¥ìƒ
            await session.commit()
        
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (WAL Mode í™œì„±í™”)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DailyBar CRUD
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def upsert_bulk(self, bars: Sequence[dict], chunk_size: int = 500) -> int:
        """
        ì¼ë´‰ ë°ì´í„° Bulk Upsert (INSERT OR REPLACE)
        
        ê°™ì€ (ticker, date) ì¡°í•©ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸í•˜ê³ ,
        ì—†ìœ¼ë©´ ìƒˆë¡œ ì‚½ì…í•©ë‹ˆë‹¤.
        
        SQLiteì˜ íŒŒë¼ë¯¸í„° ì œí•œì„ í”¼í•˜ê¸° ìœ„í•´ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            bars: ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸. ê° ë”•ì…”ë„ˆë¦¬ëŠ” ë‹¤ìŒ í‚¤ë¥¼ ê°€ì§‘ë‹ˆë‹¤:
                  ticker, date, open, high, low, close, volume, vwap, transactions
            chunk_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 500)
        
        Returns:
            int: ì²˜ë¦¬ëœ ë ˆì½”ë“œ ìˆ˜
        
        Example:
            >>> bars = [
            ...     {"ticker": "AAPL", "date": "2024-12-17", "open": 150.0, ...},
            ...     {"ticker": "MSFT", "date": "2024-12-17", "open": 380.0, ...},
            ... ]
            >>> count = await db.upsert_bulk(bars)
            >>> print(f"{count}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ë¨")
        """
        if not bars:
            return 0
        
        total_count = 0
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í•  ì²˜ë¦¬
        # SQLiteëŠ” í•œ ì¿¼ë¦¬ì— 999ê°œ íŒŒë¼ë¯¸í„° ì œí•œì´ ìˆìŒ
        # ê° ë ˆì½”ë“œê°€ 9ê°œ ì»¬ëŸ¼ â†’ ì•½ 100ê°œ ë ˆì½”ë“œê°€ í•œê³„
        # ì•ˆì „í•˜ê²Œ 500ê°œì”© ì²˜ë¦¬ (9*500=4500 < SQLITE_MAX_VARIABLE_NUMBER)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for i in range(0, len(bars), chunk_size):
            chunk = bars[i:i + chunk_size]
            
            async with self.session_factory() as session:
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                # SQLite INSERT OR REPLACE ì‚¬ìš©
                # - Primary Key ì¶©ëŒ ì‹œ ê¸°ì¡´ ë ˆì½”ë“œë¥¼ ìƒˆ ê°’ìœ¼ë¡œ êµì²´
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                stmt = sqlite_insert(DailyBar).values(list(chunk))
                stmt = stmt.on_conflict_do_update(
                    index_elements=["ticker", "date"],
                    set_={
                        "open": stmt.excluded.open,
                        "high": stmt.excluded.high,
                        "low": stmt.excluded.low,
                        "close": stmt.excluded.close,
                        "volume": stmt.excluded.volume,
                        "vwap": stmt.excluded.vwap,
                        "transactions": stmt.excluded.transactions,
                    }
                )
                
                await session.execute(stmt)
                await session.commit()
            
            total_count += len(chunk)
        
        logger.debug(f"ğŸ“Š {total_count}ê°œ ì¼ë´‰ ë°ì´í„° Upsert ì™„ë£Œ")
        return total_count
    
    async def get_daily_bars(
        self, 
        ticker: str, 
        days: int = 20,
        end_date: Optional[str] = None
    ) -> list[DailyBar]:
        """
        íŠ¹ì • ì¢…ëª©ì˜ ìµœê·¼ Nì¼ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ
        
        Seismograph ì „ëµì˜ ë§¤ì§‘ íƒì§€ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
        ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœì‹  ë°ì´í„°ë¶€í„° ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            ticker: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: "AAPL")
            days: ê°€ì ¸ì˜¬ ì¼ìˆ˜ (ê¸°ë³¸ê°’: 20)
            end_date: ì¡°íšŒ ì¢…ë£Œì¼ (ê¸°ë³¸ê°’: None = ì˜¤ëŠ˜)
        
        Returns:
            list[DailyBar]: ì¼ë´‰ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        
        Example:
            >>> bars = await db.get_daily_bars("AAPL", days=20)
            >>> for bar in bars:
            ...     print(f"{bar.date}: Close={bar.close}")
        """
        async with self.session_factory() as session:
            query = (
                select(DailyBar)
                .where(DailyBar.ticker == ticker)
            )
            
            if end_date:
                query = query.where(DailyBar.date <= end_date)
            
            query = query.order_by(DailyBar.date.desc()).limit(days)
            
            result = await session.execute(query)
            return list(result.scalars().all())
    
    async def get_latest_date(self) -> Optional[str]:
        """
        DBì— ì €ì¥ëœ ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì¡°íšŒ
        
        ì¦ë¶„ ì—…ë°ì´íŠ¸ ì‹œ ì´ ë‚ ì§œ ì´í›„ì˜ ë°ì´í„°ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Returns:
            str | None: ê°€ì¥ ìµœê·¼ ë‚ ì§œ (YYYY-MM-DD) ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None
        
        Example:
            >>> latest = await db.get_latest_date()
            >>> print(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {latest}")  # "2024-12-16"
        """
        async with self.session_factory() as session:
            result = await session.execute(
                select(DailyBar.date)
                .order_by(DailyBar.date.desc())
                .limit(1)
            )
            row = result.scalar_one_or_none()
            return row
    
    async def get_all_tickers_with_data(self) -> list[str]:
        """
        ë°ì´í„°ê°€ ìˆëŠ” ëª¨ë“  ì¢…ëª© ì‹¬ë³¼ ì¡°íšŒ
        
        Universe Filter ì ìš© ì „ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Returns:
            list[str]: ì¢…ëª© ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        """
        async with self.session_factory() as session:
            result = await session.execute(
                select(DailyBar.ticker).distinct()
            )
            return [row[0] for row in result.all()]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ticker CRUD
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def update_fundamentals(self, tickers: Sequence[dict]) -> int:
        """
        ì¢…ëª© í€ë”ë©˜í„¸ ì •ë³´ Bulk Upsert
        
        Args:
            tickers: ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸. ê° ë”•ì…”ë„ˆë¦¬ëŠ” ë‹¤ìŒ í‚¤ë¥¼ ê°€ì§‘ë‹ˆë‹¤:
                     ticker, name, market_cap, outstanding_shares, 
                     float_shares, primary_exchange, last_updated
        
        Returns:
            int: ì²˜ë¦¬ëœ ë ˆì½”ë“œ ìˆ˜
        """
        if not tickers:
            return 0
        
        async with self.session_factory() as session:
            stmt = sqlite_insert(Ticker).values(tickers)
            stmt = stmt.on_conflict_do_update(
                index_elements=["ticker"],
                set_={
                    "name": stmt.excluded.name,
                    "market_cap": stmt.excluded.market_cap,
                    "outstanding_shares": stmt.excluded.outstanding_shares,
                    "float_shares": stmt.excluded.float_shares,
                    "primary_exchange": stmt.excluded.primary_exchange,
                    "last_updated": stmt.excluded.last_updated,
                }
            )
            
            await session.execute(stmt)
            await session.commit()
        
        logger.debug(f"ğŸ“‹ {len(tickers)}ê°œ ì¢…ëª© í€ë”ë©˜í„¸ Upsert ì™„ë£Œ")
        return len(tickers)
    
    async def get_ticker_info(self, ticker: str) -> Optional[Ticker]:
        """
        íŠ¹ì • ì¢…ëª©ì˜ ë©”íƒ€ì •ë³´ ì¡°íšŒ
        
        Args:
            ticker: ì¢…ëª© ì‹¬ë³¼
        
        Returns:
            Ticker | None: ì¢…ëª© ì •ë³´ ë˜ëŠ” ì—†ìœ¼ë©´ None
        """
        async with self.session_factory() as session:
            result = await session.execute(
                select(Ticker).where(Ticker.ticker == ticker)
            )
            return result.scalar_one_or_none()
    
    async def get_universe_candidates(
        self,
        min_price: float = 2.0,
        max_price: float = 10.0,
        min_market_cap: float = 50_000_000,  # $50M
        max_market_cap: float = 300_000_000,  # $300M
        max_float: float = 15_000_000,  # 15M shares
        min_volume: int = 100_000,
    ) -> list[str]:
        """
        Universe Filter ì¡°ê±´ì— ë§ëŠ” ì¢…ëª© ì¡°íšŒ
        
        masterplan.md 3.1ì ˆ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤:
        - Price: $2.00 ~ $10.00
        - Market Cap: $50M ~ $300M
        - Float: < 15M shares
        - Avg Volume: > 100K/day
        
        Args:
            min_price, max_price: ê°€ê²© ë²”ìœ„
            min_market_cap, max_market_cap: ì‹œê°€ì´ì•¡ ë²”ìœ„
            max_float: ìµœëŒ€ Float
            min_volume: ìµœì†Œ í‰ê·  ê±°ë˜ëŸ‰
        
        Returns:
            list[str]: ì¡°ê±´ì— ë§ëŠ” ì¢…ëª© ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        """
        # TODO: ì‹¤ì œ êµ¬í˜„ ì‹œ DailyBarì™€ Tickerë¥¼ JOINí•˜ì—¬ í•„í„°ë§
        # í˜„ì¬ëŠ” Ticker í…Œì´ë¸”ë§Œìœ¼ë¡œ ê¸°ë³¸ í•„í„°ë§
        async with self.session_factory() as session:
            query = (
                select(Ticker.ticker)
                .where(Ticker.market_cap >= min_market_cap)
                .where(Ticker.market_cap <= max_market_cap)
                .where(Ticker.float_shares <= max_float)
            )
            
            result = await session.execute(query)
            return [row[0] for row in result.all()]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ìœ í‹¸ë¦¬í‹°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def get_stats(self) -> dict:
        """
        ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ
        
        Returns:
            dict: í†µê³„ ì •ë³´
                  - total_bars: ì´ ì¼ë´‰ ë ˆì½”ë“œ ìˆ˜
                  - total_tickers: ì´ ì¢…ëª© ìˆ˜
                  - latest_date: ê°€ì¥ ìµœê·¼ ë‚ ì§œ
                  - oldest_date: ê°€ì¥ ì˜¤ë˜ëœ ë‚ ì§œ
        """
        async with self.session_factory() as session:
            # ì´ ë ˆì½”ë“œ ìˆ˜
            bar_count = await session.execute(
                text("SELECT COUNT(*) FROM daily_bars")
            )
            total_bars = bar_count.scalar() or 0
            
            ticker_count = await session.execute(
                text("SELECT COUNT(*) FROM tickers")
            )
            total_tickers = ticker_count.scalar() or 0
            
            # ë‚ ì§œ ë²”ìœ„
            dates = await session.execute(
                text("SELECT MIN(date), MAX(date) FROM daily_bars")
            )
            date_row = dates.one_or_none()
            oldest_date = date_row[0] if date_row else None
            latest_date = date_row[1] if date_row else None
        
        return {
            "total_bars": total_bars,
            "total_tickers": total_tickers,
            "oldest_date": oldest_date,
            "latest_date": latest_date,
        }
    
    async def close(self) -> None:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
        
        ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ í˜¸ì¶œí•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
        """
        await self.engine.dispose()
        logger.debug("ğŸ—„ï¸ MarketDB ì—°ê²° ì¢…ë£Œ")
