# ============================================================================
# SQLite â†’ Parquet ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================
# ğŸ“Œ ì´ íŒŒì¼ì˜ ì—­í• :
#   - ê¸°ì¡´ SQLite (market_data.db)ì˜ ì¼ë´‰ ë°ì´í„°ë¥¼ Parquetìœ¼ë¡œ ë³€í™˜
#   - í‹°ì»¤ë³„ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë§ˆì´ê·¸ë ˆì´ì…˜
#   - ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ (row count, checksum)
#
# ğŸ“– ì‹¤í–‰ ë°©ë²•:
#   python -m backend.scripts.migrate_to_parquet
#   python -m backend.scripts.migrate_to_parquet --verify-only
# ============================================================================

import asyncio
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import pandas as pd
from tqdm import tqdm
from loguru import logger

from backend.data.database import MarketDB
from backend.data.parquet_manager import ParquetManager


async def migrate_daily_data(
    db_path: str = "data/market_data.db",
    parquet_dir: str = "data/parquet",
    batch_size: int = 50,
) -> dict:
    """
    SQLite â†’ Parquet ì¼ë´‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜

    Args:
        db_path: SQLite DB ê²½ë¡œ
        parquet_dir: Parquet ì €ì¥ ë””ë ‰í„°ë¦¬
        batch_size: í‹°ì»¤ë‹¹ ë°°ì¹˜ í¬ê¸°

    Returns:
        dict: ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼
            - total_tickers: ì „ì²´ í‹°ì»¤ ìˆ˜
            - total_rows: ì „ì²´ ë ˆì½”ë“œ ìˆ˜
            - elapsed_seconds: ì†Œìš” ì‹œê°„
    """
    import time

    start_time = time.time()

    # ì´ˆê¸°í™”
    db = MarketDB(db_path)
    await db.initialize()
    pm = ParquetManager(parquet_dir)

    logger.info("ğŸš€ SQLite â†’ Parquet ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info(f"   Source: {db_path}")
    logger.info(f"   Target: {parquet_dir}")

    # ëª¨ë“  í‹°ì»¤ ì¡°íšŒ
    tickers = await db.get_all_tickers_with_data()
    logger.info(f"ğŸ“Š ì´ {len(tickers)}ê°œ í‹°ì»¤ ë°œê²¬")

    if not tickers:
        logger.warning("âš ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        await db.close()
        return {"total_tickers": 0, "total_rows": 0, "elapsed_seconds": 0}

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
    all_rows = []
    for i in tqdm(range(0, len(tickers), batch_size), desc="Migrating"):
        batch_tickers = tickers[i : i + batch_size]

        for ticker in batch_tickers:
            # í•´ë‹¹ í‹°ì»¤ì˜ ëª¨ë“  ì¼ë´‰ ë°ì´í„° ì¡°íšŒ
            bars = await db.get_daily_bars(ticker, days=365 * 5)  # ìµœëŒ€ 5ë…„ì¹˜
            if bars:
                for bar in bars:
                    all_rows.append(bar.to_dict())

    # Parquetìœ¼ë¡œ ì €ì¥
    if all_rows:
        df = pd.DataFrame(all_rows)
        pm.write_daily(df)
        logger.info(f"âœ… {len(all_rows)} ë ˆì½”ë“œ Parquet ì €ì¥ ì™„ë£Œ")

    elapsed = time.time() - start_time
    await db.close()

    result = {
        "total_tickers": len(tickers),
        "total_rows": len(all_rows),
        "elapsed_seconds": round(elapsed, 2),
    }

    logger.info(f"ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ! {result}")
    return result


async def verify_migration(
    db_path: str = "data/market_data.db",
    parquet_dir: str = "data/parquet",
) -> dict:
    """
    ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

    Args:
        db_path: SQLite DB ê²½ë¡œ
        parquet_dir: Parquet ë””ë ‰í„°ë¦¬

    Returns:
        dict: ê²€ì¦ ê²°ê³¼
            - sqlite_rows: SQLite ë ˆì½”ë“œ ìˆ˜
            - parquet_rows: Parquet ë ˆì½”ë“œ ìˆ˜
            - match: ì¼ì¹˜ ì—¬ë¶€
    """
    db = MarketDB(db_path)
    await db.initialize()
    pm = ParquetManager(parquet_dir)

    # SQLite ë ˆì½”ë“œ ìˆ˜
    stats = await db.get_stats()
    sqlite_rows = stats["total_bars"]

    # Parquet ë ˆì½”ë“œ ìˆ˜
    parquet_stats = pm.get_stats()
    parquet_rows = parquet_stats["daily_rows"]

    match = sqlite_rows == parquet_rows

    await db.close()

    result = {
        "sqlite_rows": sqlite_rows,
        "parquet_rows": parquet_rows,
        "match": match,
    }

    if match:
        logger.info(f"âœ… ê²€ì¦ ì„±ê³µ: {sqlite_rows} ë ˆì½”ë“œ ì¼ì¹˜")
    else:
        logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: SQLite={sqlite_rows}, Parquet={parquet_rows}")

    return result


async def main():
    """CLI ì§„ì…ì """
    import argparse

    parser = argparse.ArgumentParser(description="SQLite â†’ Parquet ë§ˆì´ê·¸ë ˆì´ì…˜")
    parser.add_argument(
        "--verify-only", action="store_true", help="ê²€ì¦ë§Œ ìˆ˜í–‰ (ë§ˆì´ê·¸ë ˆì´ì…˜ ì—†ì´)"
    )
    parser.add_argument(
        "--db-path", default="data/market_data.db", help="SQLite DB ê²½ë¡œ"
    )
    parser.add_argument(
        "--parquet-dir", default="data/parquet", help="Parquet ì €ì¥ ë””ë ‰í„°ë¦¬"
    )

    args = parser.parse_args()

    if args.verify_only:
        await verify_migration(args.db_path, args.parquet_dir)
    else:
        await migrate_daily_data(args.db_path, args.parquet_dir)
        await verify_migration(args.db_path, args.parquet_dir)


if __name__ == "__main__":
    asyncio.run(main())
