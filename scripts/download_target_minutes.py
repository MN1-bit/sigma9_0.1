"""
R-4 Target-Based Minute Data Download

control_groups.csvì˜ (ticker, date) ì¡°í•©ì— ëŒ€í•´ í•´ë‹¹ ë‚ ì§œ ë¶„ë´‰ë§Œ ë‹¤ìš´ë¡œë“œ.
ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ ~8ë¶„ ì˜ˆìƒ.

Usage:
    python scripts/download_target_minutes.py
    python scripts/download_target_minutes.py --test     # 10ê±´ë§Œ í…ŒìŠ¤íŠ¸
    python scripts/download_target_minutes.py --reset    # ì§„í–‰ ì´ˆê¸°í™”
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path

import pandas as pd
from loguru import logger

# Project root
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv  # noqa: E402

load_dotenv(project_root / ".env")

from backend.data.massive_client import MassiveClient  # noqa: E402
from backend.data.parquet_manager import ParquetManager  # noqa: E402

# ==================================================
# ì„¤ì •
# ==================================================
CONTROL_CSV = Path("scripts/control_groups.csv")
COVERAGE_CSV = Path("scripts/minute_coverage_report.csv")
PARQUET_DIR = Path("data/parquet")
PROGRESS_FILE = Path("data/target_download_progress.json")

# Rate limit: Massive API ~100 req/min = 0.6ì´ˆ/í˜¸ì¶œ
REQUEST_DELAY = 0.65
MAX_CONCURRENT = 5  # ë™ì‹œ ìš”ì²­ ìˆ˜ (ë³´ìˆ˜ì  ì‹œì‘)


# ==================================================
# ì§„í–‰ ìƒí™© ê´€ë¦¬
# ==================================================


def load_progress() -> set:
    """ì™„ë£Œëœ (ticker, date) ì¡°í•© ë¡œë“œ."""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE) as f:
            data = json.load(f)
            return set(tuple(x) for x in data.get("completed", []))
    return set()


def save_progress(completed: set) -> None:
    """ì§„í–‰ ìƒí™© ì €ì¥."""
    PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(PROGRESS_FILE, "w") as f:
        json.dump(
            {
                "completed": [list(x) for x in completed],
                "last_updated": datetime.now().isoformat(),
            },
            f,
        )


# ==================================================
# íƒ€ê²Ÿ ë¡œë“œ
# ==================================================


def load_targets() -> list[tuple[str, str]]:
    """
    control_groups.csvì—ì„œ ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ì¶”ì¶œ.
    
    Returns:
        [(ticker, date_str), ...] ê³ ìœ  ì¡°í•© ë¦¬ìŠ¤íŠ¸
    """
    df = pd.read_csv(CONTROL_CSV)
    
    targets = set()
    
    # Daygainer
    for _, row in df.iterrows():
        targets.add((row["daygainer_ticker"], str(row["daygainer_date"])))
    
    # Control
    for _, row in df.iterrows():
        targets.add((row["control_ticker"], str(row["daygainer_date"])))
    
    logger.info(f"ğŸ“‹ ê³ ìœ  (ticker, date) ì¡°í•©: {len(targets)}ê±´")
    return list(targets)


# ==================================================
# ë‹¤ìš´ë¡œë“œ
# ==================================================


async def download_one(
    client: MassiveClient,
    pm: ParquetManager,
    ticker: str,
    date_str: str,
    semaphore: asyncio.Semaphore,
) -> bool:
    """
    ë‹¨ì¼ (ticker, date) ë¶„ë´‰ ë‹¤ìš´ë¡œë“œ.
    
    í•´ë‹¹ ë‚ ì§œ 04:00 ~ 20:00 ET ë²”ìœ„ ë‹¤ìš´ë¡œë“œ.
    """
    async with semaphore:
        try:
            # í•˜ë£¨ì¹˜ ë²”ìœ„ (í”„ë¦¬ë§ˆì¼“/ì• í”„í„°ë§ˆì¼“ í¬í•¨)
            bars = await client.fetch_intraday_bars(
                ticker=ticker,
                multiplier=1,
                from_date=date_str,
                to_date=date_str,
                limit=1000,  # í•˜ë£¨ì¹˜ ~960ë¶„ë´‰
            )
            
            if bars:
                df = pd.DataFrame(bars)
                pm.append_intraday(ticker, "1m", df)
                return True
            return False
            
        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} {date_str} ì‹¤íŒ¨: {e}")
            return False
        finally:
            await asyncio.sleep(REQUEST_DELAY)


async def download_targets(test_mode: bool = False) -> None:
    """íƒ€ê²Ÿ ê¸°ë°˜ ë¶„ë´‰ ë‹¤ìš´ë¡œë“œ ë©”ì¸."""
    logger.info("=" * 60)
    logger.info("ğŸ“¥ R-4 Target-Based Minute Download")
    logger.info("=" * 60)
    
    # íƒ€ê²Ÿ ë¡œë“œ
    all_targets = load_targets()
    
    # ì§„í–‰ ìƒí™© ë³µì›
    completed = load_progress()
    remaining = [t for t in all_targets if t not in completed]
    
    logger.info(f"ğŸ“Œ ì „ì²´: {len(all_targets)}ê±´, ì™„ë£Œ: {len(completed)}ê±´, ë‚¨ìŒ: {len(remaining)}ê±´")
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if test_mode:
        remaining = remaining[:10]
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {len(remaining)}ê±´ë§Œ ì²˜ë¦¬")
    
    if not remaining:
        logger.info("âœ… ëª¨ë“  íƒ€ê²Ÿ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return
    
    # API í´ë¼ì´ì–¸íŠ¸
    api_key = os.environ.get("MASSIVE_API_KEY")
    if not api_key:
        logger.error("âŒ MASSIVE_API_KEY í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")
        return
    
    pm = ParquetManager(str(PARQUET_DIR))
    semaphore = asyncio.Semaphore(MAX_CONCURRENT)
    
    async with MassiveClient(api_key=api_key) as client:
        total = len(remaining)
        success = 0
        errors = 0
        start_time = datetime.now()
        
        for i, (ticker, date_str) in enumerate(remaining):
            result = await download_one(client, pm, ticker, date_str, semaphore)
            
            if result:
                success += 1
                completed.add((ticker, date_str))
            else:
                errors += 1
            
            # 50ê±´ë§ˆë‹¤ ì €ì¥ ë° ë¡œê·¸
            if (i + 1) % 50 == 0:
                save_progress(completed)
                elapsed = (datetime.now() - start_time).total_seconds()
                rate = (i + 1) / elapsed if elapsed > 0 else 0
                eta = (total - i - 1) / rate / 60 if rate > 0 else 0
                
                logger.info(
                    f"ğŸ“Š {i + 1}/{total} ({(i + 1) / total * 100:.1f}%) "
                    f"| ì„±ê³µ: {success} | ì˜¤ë¥˜: {errors} "
                    f"| ETA: {eta:.1f}ë¶„"
                )
    
    # ì™„ë£Œ
    save_progress(completed)
    elapsed = (datetime.now() - start_time).total_seconds() / 60
    
    logger.info("=" * 60)
    logger.info("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    logger.info(f"ğŸ“Š ì„±ê³µ: {success}/{total} ({success / total * 100:.1f}%)")
    logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.1f}ë¶„")
    logger.info("=" * 60)


# ==================================================
# CLI
# ==================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="R-4 Target Minute Download")
    parser.add_argument("--test", action="store_true", help="Test mode (10 targets only)")
    parser.add_argument("--reset", action="store_true", help="Reset progress")
    args = parser.parse_args()
    
    if args.reset and PROGRESS_FILE.exists():
        PROGRESS_FILE.unlink()
        logger.info("ğŸ—‘ï¸ Progress reset")
    
    asyncio.run(download_targets(test_mode=args.test))
