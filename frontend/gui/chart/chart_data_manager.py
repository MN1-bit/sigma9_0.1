# ============================================================================
# Chart Data Manager - 2-Tier Cache for Dynamic Data Loading (Step 2.7.4)
# ============================================================================
# ğŸ“Œ ì´ íŒŒì¼ì˜ ì—­í• :
#   - ì°¨íŠ¸ Pan/Zoom ì‹œ 2-Tier Cacheë¥¼ í™œìš©í•œ ë™ì  ë°ì´í„° ë¡œë”© ê´€ë¦¬
#   - L1: Memory Cache (í˜„ì¬ ë·°í¬íŠ¸ + ë²„í¼)
#   - L2: SQLite Database (ê³¼ê±° ë°ì´í„°)
#   - L3: Massive API (DBì— ì—†ëŠ” ë°ì´í„° fetch)
#
# ğŸ—ï¸ ì•„í‚¤í…ì²˜:
#   Viewport Changed â†’ needs_more_data() â†’ L1 Miss â†’ L2 Query â†’ L3 Fetch
#                                                         â†“
#                                                    Save to L2
# ============================================================================

"""
Chart Data Manager

Pan/Zoom ì‹œ ë™ì  ë°ì´í„° ë¡œë”©ì„ ìœ„í•œ 2-Tier Cache ê´€ë¦¬ìì…ë‹ˆë‹¤.

Features:
    - ë·°í¬íŠ¸ ë²”ìœ„ ê¸°ë°˜ ë°ì´í„° í•„ìš” ì—¬ë¶€ íŒë‹¨
    - Memory + SQLite 2-tier ìºì‹±
    - ë°ì´í„° ë³‘í•© (prepend/append)
    - ë²„í¼ë§ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ìŠ¤í¬ë¡¤ ê²½í—˜
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import pandas as pd
from loguru import logger


@dataclass
class LoadedRange:
    """ë¡œë“œëœ ë°ì´í„° ë²”ìœ„ ì¶”ì """
    start_idx: int
    end_idx: int
    start_timestamp: int  # Unix ms
    end_timestamp: int    # Unix ms


class ChartDataManager:
    """
    ì°¨íŠ¸ ë°ì´í„° ìºì‹± ë° ë™ì  ë¡œë”© ê´€ë¦¬ì
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ELI5 (ì‰¬ìš´ ì„¤ëª…):
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ì°¨íŠ¸ë¥¼ ìŠ¤í¬ë¡¤í•˜ë©´ ë³´ì´ì§€ ì•ŠëŠ” ê³¼ê±° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    ì´ í´ë˜ìŠ¤ëŠ” "ì–´ë–¤ ë°ì´í„°ê°€ í•„ìš”í•œì§€" íŒë‹¨í•˜ê³ ,
    "DBì—ì„œ ê°€ì ¸ì˜¬ì§€, APIì—ì„œ ê°€ì ¸ì˜¬ì§€" ê²°ì •í•©ë‹ˆë‹¤.
    
    L1: ë©”ëª¨ë¦¬ (ë¹ ë¦„, ìš©ëŸ‰ ì‘ìŒ) - ì§€ê¸ˆ ë³´ì´ëŠ” ë°ì´í„°
    L2: SQLite (ì¤‘ê°„) - ê³¼ê±° ì €ì¥ëœ ë°ì´í„°
    L3: API (ëŠë¦¼) - DBì— ì—†ìœ¼ë©´ API í˜¸ì¶œ
    
    Attributes:
        FETCH_BUFFER: ë·°í¬íŠ¸ ì–‘ìª½ì— ë¯¸ë¦¬ ë¡œë“œí•  ë°” ìˆ˜
        MIN_FETCH_SIZE: ìµœì†Œ fetch í¬ê¸° (API íš¨ìœ¨ì„±)
    """
    
    FETCH_BUFFER = 50  # ë·°í¬íŠ¸ ì–‘ìª½ì— ë¯¸ë¦¬ ë¡œë“œí•  ë°” ìˆ˜
    MIN_FETCH_SIZE = 100  # ìµœì†Œ fetch í¬ê¸° (API íš¨ìœ¨ì„±)
    
    def __init__(self):
        """ChartDataManager ì´ˆê¸°í™”"""
        self._loaded_range: Optional[LoadedRange] = None
        self._data_cache: List[Dict[str, Any]] = []  # L1: Memory Cache
        self._current_ticker: Optional[str] = None
        self._current_timeframe: str = "1D"
        
        logger.debug("ğŸ“Š ChartDataManager ì´ˆê¸°í™”")
    
    @property
    def loaded_range(self) -> Optional[LoadedRange]:
        """í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ë²”ìœ„"""
        return self._loaded_range
    
    @property
    def data_cache(self) -> List[Dict[str, Any]]:
        """í˜„ì¬ ìºì‹œëœ ë°ì´í„° (L1)"""
        return self._data_cache
    
    def reset(self, ticker: str = None, timeframe: str = None):
        """
        íƒ€ì„í”„ë ˆì„ ë˜ëŠ” ì¢…ëª© ë³€ê²½ ì‹œ ìºì‹œ ì´ˆê¸°í™”
        
        Args:
            ticker: ìƒˆ ì¢…ëª© ì‹¬ë³¼
            timeframe: ìƒˆ íƒ€ì„í”„ë ˆì„
        """
        self._loaded_range = None
        self._data_cache = []
        
        if ticker:
            self._current_ticker = ticker
        if timeframe:
            self._current_timeframe = timeframe
        
        logger.debug(f"ğŸ”„ Cache ì´ˆê¸°í™”: {self._current_ticker} / {self._current_timeframe}")
    
    def set_initial_data(self, data: List[Dict[str, Any]]):
        """
        ì´ˆê¸° ë°ì´í„° ì„¤ì •
        
        Args:
            data: ì°¨íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{"time": timestamp, "open": float, ...}, ...]
        """
        if not data:
            return
        
        self._data_cache = data.copy()
        
        # ë²”ìœ„ ê³„ì‚°
        timestamps = [d.get("time", 0) for d in data]
        if timestamps:
            self._loaded_range = LoadedRange(
                start_idx=0,
                end_idx=len(data) - 1,
                start_timestamp=int(min(timestamps) * 1000),  # seconds â†’ ms
                end_timestamp=int(max(timestamps) * 1000)
            )
        
        logger.debug(
            f"ğŸ“¥ ì´ˆê¸° ë°ì´í„° ì„¤ì •: {len(data)} bars, "
            f"range=[{self._loaded_range.start_idx}:{self._loaded_range.end_idx}]"
        )
    
    def needs_more_data(self, view_start: int, view_end: int) -> bool:
        """
        ì¶”ê°€ ë°ì´í„° ë¡œë“œ í•„ìš” ì—¬ë¶€ í™•ì¸
        
        ë·°í¬íŠ¸ê°€ ë²„í¼ ë²”ìœ„ ë°–ìœ¼ë¡œ ë‚˜ê°€ë©´ True ë°˜í™˜
        
        Args:
            view_start: ë·°í¬íŠ¸ ì‹œì‘ ì¸ë±ìŠ¤
            view_end: ë·°í¬íŠ¸ ë ì¸ë±ìŠ¤
        
        Returns:
            bool: ì¶”ê°€ ë°ì´í„° í•„ìš” ì—¬ë¶€
        """
        if self._loaded_range is None:
            return True
        
        # ë·°í¬íŠ¸ê°€ ë²„í¼ ë²”ìœ„ ë°–ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€ í™•ì¸
        buffer_start = self._loaded_range.start_idx + self.FETCH_BUFFER
        buffer_end = self._loaded_range.end_idx - self.FETCH_BUFFER
        
        needs_left = view_start < buffer_start and view_start < 0
        needs_right = view_end > buffer_end  # ì˜¤ë¥¸ìª½ì€ ë¯¸ë˜ â†’ ë³´í†µ í•„ìš” ì—†ìŒ
        
        # ì™¼ìª½(ê³¼ê±°) ë°©í–¥ìœ¼ë¡œë§Œ ë™ì  ë¡œë”© ì§€ì› (ì˜¤ë¥¸ìª½ì€ ìµœì‹  ë°ì´í„°)
        return needs_left
    
    def calculate_fetch_range(
        self, 
        view_start: int, 
        view_end: int
    ) -> tuple[int, int, int, int]:
        """
        Fetchí•  ë°ì´í„° ë²”ìœ„ ê³„ì‚°
        
        Args:
            view_start: ë·°í¬íŠ¸ ì‹œì‘ ì¸ë±ìŠ¤
            view_end: ë·°í¬íŠ¸ ë ì¸ë±ìŠ¤
        
        Returns:
            (fetch_start_idx, fetch_end_idx, start_ts, end_ts)
            - fetch_start_idx: ì¸ë±ìŠ¤ ì‹œì‘ (ìŒìˆ˜ ê°€ëŠ¥)
            - fetch_end_idx: ì¸ë±ìŠ¤ ë
            - start_ts: ì‹œì‘ íƒ€ì„ìŠ¤íƒ¬í”„ (ë°€ë¦¬ì´ˆ)
            - end_ts: ë íƒ€ì„ìŠ¤íƒ¬í”„ (ë°€ë¦¬ì´ˆ)
        """
        if self._loaded_range is None:
            return 0, self.MIN_FETCH_SIZE, 0, 0
        
        # ë·°í¬íŠ¸ + ë²„í¼ ë²”ìœ„ ê³„ì‚°
        desired_start = view_start - self.FETCH_BUFFER * 2
        
        # ì´ë¯¸ ë¡œë“œëœ ë²”ìœ„ ì œì™¸ â†’ ì™¼ìª½(ê³¼ê±°)ë§Œ fetch
        fetch_start_idx = desired_start
        fetch_end_idx = self._loaded_range.start_idx - 1
        
        # ìµœì†Œ fetch í¬ê¸° ë³´ì¥
        if fetch_end_idx - fetch_start_idx < self.MIN_FETCH_SIZE:
            fetch_start_idx = fetch_end_idx - self.MIN_FETCH_SIZE
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚° (ì¸ë±ìŠ¤ â†’ íƒ€ì„ìŠ¤íƒ¬í”„)
        # í˜„ì¬ ë°ì´í„°ì˜ í‰ê·  ê°„ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
        avg_interval = self._estimate_bar_interval()
        
        start_ts = self._loaded_range.start_timestamp - abs(fetch_end_idx - fetch_start_idx) * avg_interval
        end_ts = self._loaded_range.start_timestamp - avg_interval
        
        return fetch_start_idx, fetch_end_idx, int(start_ts), int(end_ts)
    
    def _estimate_bar_interval(self) -> int:
        """
        ë°” ê°„ê²© ì¶”ì • (ë°€ë¦¬ì´ˆ)
        
        í˜„ì¬ íƒ€ì„í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë°” ê°„ê²©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        tf = self._current_timeframe.lower()
        
        if tf == "1m":
            return 60 * 1000
        elif tf == "5m":
            return 5 * 60 * 1000
        elif tf == "15m":
            return 15 * 60 * 1000
        elif tf == "1h":
            return 60 * 60 * 1000
        elif tf == "1d":
            return 24 * 60 * 60 * 1000
        else:
            # ê¸°ë³¸ê°’: 5ë¶„
            return 5 * 60 * 1000
    
    def merge_data(self, new_data: List[Dict[str, Any]], prepend: bool = False):
        """
        ìƒˆ ë°ì´í„°ë¥¼ ê¸°ì¡´ ìºì‹œì— ë³‘í•©
        
        Args:
            new_data: ìƒˆë¡œ ë¡œë“œëœ ë°ì´í„°
            prepend: Trueë©´ ì•ìª½(ê³¼ê±°), Falseë©´ ë’¤ìª½(ë¯¸ë˜)ì— ì¶”ê°€
        """
        if not new_data:
            return
        
        if not self._data_cache:
            self.set_initial_data(new_data)
            return
        
        if prepend:
            # ì•ìª½(ê³¼ê±°)ì— ì¶”ê°€
            self._data_cache = new_data + self._data_cache
            
            # ë²”ìœ„ ì—…ë°ì´íŠ¸
            if self._loaded_range:
                self._loaded_range.start_idx -= len(new_data)
                new_timestamps = [d.get("time", 0) for d in new_data]
                if new_timestamps:
                    self._loaded_range.start_timestamp = int(min(new_timestamps) * 1000)
            
            logger.debug(f"â¬…ï¸ {len(new_data)} bars prepended, new start_idx={self._loaded_range.start_idx}")
        else:
            # ë’¤ìª½(ë¯¸ë˜)ì— ì¶”ê°€
            self._data_cache.extend(new_data)
            
            # ë²”ìœ„ ì—…ë°ì´íŠ¸
            if self._loaded_range:
                self._loaded_range.end_idx += len(new_data)
                new_timestamps = [d.get("time", 0) for d in new_data]
                if new_timestamps:
                    self._loaded_range.end_timestamp = int(max(new_timestamps) * 1000)
            
            logger.debug(f"â¡ï¸ {len(new_data)} bars appended, new end_idx={self._loaded_range.end_idx}")
    
    def get_visible_data(
        self, 
        start_idx: int, 
        end_idx: int
    ) -> List[Dict[str, Any]]:
        """
        ë·°í¬íŠ¸ì— í‘œì‹œí•  ë°ì´í„° ë°˜í™˜
        
        Args:
            start_idx: ì‹œì‘ ì¸ë±ìŠ¤ (ìŒìˆ˜ ê°€ëŠ¥ = ê³¼ê±° ë°©í–¥)
            end_idx: ë ì¸ë±ìŠ¤
        
        Returns:
            list[dict]: í•´ë‹¹ ë²”ìœ„ì˜ ë°ì´í„°
        """
        if not self._data_cache or self._loaded_range is None:
            return []
        
        # ìºì‹œ ë‚´ ìƒëŒ€ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        relative_start = max(0, start_idx - self._loaded_range.start_idx)
        relative_end = min(
            len(self._data_cache),
            end_idx - self._loaded_range.start_idx + 1
        )
        
        if relative_start >= relative_end:
            return []
        
        return self._data_cache[relative_start:relative_end]
    
    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜ (ë””ë²„ê·¸ìš©)"""
        return {
            "ticker": self._current_ticker,
            "timeframe": self._current_timeframe,
            "cache_size": len(self._data_cache),
            "loaded_range": {
                "start_idx": self._loaded_range.start_idx if self._loaded_range else None,
                "end_idx": self._loaded_range.end_idx if self._loaded_range else None,
            } if self._loaded_range else None
        }
