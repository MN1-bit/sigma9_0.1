# ============================================================================
# ë°ì´í„° ì •í•©ì„± ìœ ë‹› í…ŒìŠ¤íŠ¸ (11-004)
# ============================================================================
# ğŸ“Œ ì´ íŒŒì¼ì˜ ì—­í• :
#   - validators.py í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
#   - repair_parquet_data.py DataRepairer í…ŒìŠ¤íŠ¸
#   - Dry-run ëª¨ë“œ ê²€ì¦
# ============================================================================

"""
ë°ì´í„° ì •í•©ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸ (11-004)

validators ëª¨ë“ˆê³¼ DataRepairer í´ë˜ìŠ¤ì˜ ìœ ë‹› í…ŒìŠ¤íŠ¸.
"""

import pytest
import pandas as pd
from pathlib import Path
import tempfile
import shutil

from backend.data.validators import (
    validate_ohlc_relationship,
    validate_volume,
    detect_daily_gaps,
    detect_intraday_gaps,
    detect_price_outliers,
    interpolate_outliers,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Fixtures
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@pytest.fixture
def valid_ohlc_df():
    """ì •ìƒì ì¸ OHLC ë°ì´í„°"""
    return pd.DataFrame({
        "ticker": ["AAPL", "AAPL", "AAPL"],
        "date": ["2024-01-02", "2024-01-03", "2024-01-04"],
        "open": [100.0, 102.0, 105.0],
        "high": [105.0, 108.0, 110.0],
        "low": [98.0, 100.0, 103.0],
        "close": [103.0, 106.0, 108.0],
        "volume": [1000000, 1200000, 1100000],
    })


@pytest.fixture
def invalid_ohlc_df():
    """OHLC ê´€ê³„ ìœ„ë°˜ ë°ì´í„°"""
    return pd.DataFrame({
        "ticker": ["AAPL", "AAPL", "AAPL"],
        "date": ["2024-01-02", "2024-01-03", "2024-01-04"],
        # ìœ„ë°˜ 1: High < Low (row 0)
        # ìœ„ë°˜ 2: High < Close (row 1)
        # ìœ„ë°˜ 3: Low > Open (row 2)
        "open": [100.0, 102.0, 105.0],
        "high": [95.0, 104.0, 110.0],   # row 0: High(95) < Low(98)
        "low": [98.0, 100.0, 107.0],    # row 2: Low(107) > Open(105)
        "close": [103.0, 106.0, 108.0],  # row 1: High(104) < Close(106)
        "volume": [1000000, 1200000, 1100000],
    })


@pytest.fixture
def temp_parquet_dir():
    """ì„ì‹œ Parquet ë””ë ‰í„°ë¦¬"""
    temp_dir = Path(tempfile.mkdtemp())
    daily_dir = temp_dir / "daily"
    daily_dir.mkdir(parents=True)
    yield temp_dir
    shutil.rmtree(temp_dir)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OHLC ê²€ì¦ í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestValidateOHLC:
    """OHLC ê´€ê³„ ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_valid_ohlc_no_violations(self, valid_ohlc_df):
        """ì •ìƒ ë°ì´í„°ëŠ” ìœ„ë°˜ ì—†ìŒ"""
        violations = validate_ohlc_relationship(valid_ohlc_df)
        assert len(violations) == 0

    def test_detects_high_lt_low(self):
        """High < Low íƒì§€"""
        df = pd.DataFrame({
            "open": [100.0],
            "high": [95.0],   # High(95) < Low(98) ìœ„ë°˜
            "low": [98.0],
            "close": [97.0],
        })
        violations = validate_ohlc_relationship(df)
        assert any(v["violation_type"] == "high_lt_low" for v in violations)

    def test_detects_high_lt_close(self):
        """High < Close íƒì§€"""
        df = pd.DataFrame({
            "open": [100.0],
            "high": [102.0],  # High(102) < Close(105) ìœ„ë°˜
            "low": [98.0],
            "close": [105.0],
        })
        violations = validate_ohlc_relationship(df)
        assert any(v["violation_type"] == "high_lt_max_oc" for v in violations)

    def test_detects_low_gt_open(self):
        """Low > Open íƒì§€"""
        df = pd.DataFrame({
            "open": [100.0],
            "high": [110.0],
            "low": [102.0],   # Low(102) > Open(100) ìœ„ë°˜
            "close": [105.0],
        })
        violations = validate_ohlc_relationship(df)
        assert any(v["violation_type"] == "low_gt_min_oc" for v in violations)

    def test_detects_non_positive_price(self):
        """ìŒìˆ˜/0 ê°€ê²© íƒì§€"""
        df = pd.DataFrame({
            "open": [0.0],   # Open <= 0 ìœ„ë°˜
            "high": [10.0],
            "low": [5.0],
            "close": [8.0],
        })
        violations = validate_ohlc_relationship(df)
        assert any("non_positive" in v["violation_type"] for v in violations)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Volume ê²€ì¦ í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestValidateVolume:
    """Volume ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_valid_volume(self, valid_ohlc_df):
        """ì •ìƒ ê±°ë˜ëŸ‰"""
        violations = validate_volume(valid_ohlc_df)
        assert len(violations) == 0

    def test_detects_negative_volume(self):
        """ìŒìˆ˜ ê±°ë˜ëŸ‰ íƒì§€"""
        df = pd.DataFrame({
            "ticker": ["AAPL"],
            "volume": [-100],
        })
        violations = validate_volume(df)
        assert len(violations) == 1
        assert violations[0]["violation_type"] == "negative_volume"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê°­ íƒì§€ í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestDetectDailyGaps:
    """Daily ê°­ íƒì§€ í…ŒìŠ¤íŠ¸"""

    def test_no_gaps_when_complete(self):
        """ì™„ì „í•œ ë°ì´í„°ëŠ” ê°­ ì—†ìŒ"""
        df = pd.DataFrame({
            "ticker": ["AAPL", "AAPL", "AAPL"],
            "date": ["2024-01-02", "2024-01-03", "2024-01-04"],
        })
        calendar = ["2024-01-02", "2024-01-03", "2024-01-04"]
        gaps = detect_daily_gaps(df, trading_calendar=calendar)
        assert len(gaps) == 0

    def test_detects_missing_date(self):
        """ëˆ„ë½ëœ ë‚ ì§œ íƒì§€"""
        df = pd.DataFrame({
            "ticker": ["AAPL", "AAPL"],  # 2024-01-03 ëˆ„ë½
            "date": ["2024-01-02", "2024-01-04"],
        })
        calendar = ["2024-01-02", "2024-01-03", "2024-01-04"]
        gaps = detect_daily_gaps(df, trading_calendar=calendar)
        assert "AAPL" in gaps
        assert "2024-01-03" in gaps["AAPL"]


class TestDetectIntradayGaps:
    """Intraday ê°­ íƒì§€ í…ŒìŠ¤íŠ¸"""

    def test_no_gaps_continuous(self):
        """ì—°ì†ì ì¸ ë°ì´í„°ëŠ” ê°­ ì—†ìŒ"""
        timestamps = pd.date_range("2024-01-02 09:30", periods=5, freq="1min")
        df = pd.DataFrame({"timestamp": timestamps})
        gaps = detect_intraday_gaps(df, timeframe_minutes=1)
        assert len(gaps) == 0

    def test_detects_gap(self):
        """ì‹œê°„ ê°­ íƒì§€"""
        # 09:30, 09:31, 09:35 (2ë¶„ ê°­)
        df = pd.DataFrame({
            "timestamp": [
                "2024-01-02 09:30:00",
                "2024-01-02 09:31:00",
                "2024-01-02 09:35:00",  # 3ë¶„ ê°­
            ]
        })
        gaps = detect_intraday_gaps(df, timeframe_minutes=1)
        assert len(gaps) > 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestDetectOutliers:
    """ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸"""

    def test_no_outliers_in_normal_data(self):
        """ì •ìƒ ë°ì´í„°ëŠ” ì´ìƒì¹˜ ì—†ìŒ"""
        df = pd.DataFrame({
            "close": [100, 101, 102, 101, 100, 99, 100],
        })
        outliers = detect_price_outliers(df, z_threshold=3.0)
        assert len(outliers) == 0

    def test_detects_spike(self):
        """ê°€ê²© ìŠ¤íŒŒì´í¬ íƒì§€"""
        df = pd.DataFrame({
            # ì •ìƒ ë°ì´í„° í›„ 500% ê¸‰ë“±
            "close": [100, 101, 102, 101, 100, 600, 100],
        })
        outliers = detect_price_outliers(df, z_threshold=2.0)
        assert len(outliers) > 0


class TestInterpolateOutliers:
    """ì´ìƒì¹˜ ë³´ê°„ í…ŒìŠ¤íŠ¸"""

    def test_interpolates_correctly(self):
        """ì„ í˜• ë³´ê°„ ì •í™•ì„±"""
        df = pd.DataFrame({
            "open": [100.0, 200.0, 300.0],
            "high": [105.0, 205.0, 305.0],
            "low": [95.0, 195.0, 295.0],
            "close": [102.0, 202.0, 302.0],
        })
        # ì¸ë±ìŠ¤ 1ì„ ì´ìƒì¹˜ë¡œ í‘œì‹œí•˜ê³  ë³´ê°„
        result_df, report = interpolate_outliers(df, [1], method="linear")

        # ë³´ê°„ í›„ ì¤‘ê°„ê°’ì´ í‰ê· ì— ê°€ê¹Œì›Œì•¼ í•¨
        assert len(report) == 1
        assert report[0]["index"] == 1


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DataRepairer í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestDataRepairer:
    """DataRepairer í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    def test_dry_run_no_modification(self, temp_parquet_dir):
        """Dry-run ëª¨ë“œëŠ” íŒŒì¼ ìˆ˜ì • ì•ˆí•¨"""
        from backend.scripts.repair_parquet_data import DataRepairer

        # ì¤‘ë³µ ë°ì´í„° ìƒì„±
        daily_dir = temp_parquet_dir / "daily"
        df = pd.DataFrame({
            "ticker": ["AAPL", "AAPL", "AAPL"],
            "date": ["2024-01-02", "2024-01-02", "2024-01-03"],  # ì¤‘ë³µ
            "open": [100.0, 100.0, 102.0],
            "high": [105.0, 105.0, 108.0],
            "low": [98.0, 98.0, 100.0],
            "close": [103.0, 103.0, 106.0],
            "volume": [1000000, 1000000, 1200000],
        })
        df.to_parquet(daily_dir / "all_daily.parquet", index=False)

        # Dry-run ì‹¤í–‰
        repairer = DataRepairer(temp_parquet_dir, dry_run=True)
        repairer.remove_duplicates_daily()

        # íŒŒì¼ ë³€ê²½ ì—†ìŒ í™•ì¸
        result_df = pd.read_parquet(daily_dir / "all_daily.parquet")
        assert len(result_df) == 3  # ì—¬ì „íˆ 3ê°œ (ì¤‘ë³µ í¬í•¨)

    def test_apply_removes_duplicates(self, temp_parquet_dir):
        """Apply ëª¨ë“œëŠ” ì¤‘ë³µ ì œê±°"""
        from backend.scripts.repair_parquet_data import DataRepairer

        # ì¤‘ë³µ ë°ì´í„° ìƒì„±
        daily_dir = temp_parquet_dir / "daily"
        df = pd.DataFrame({
            "ticker": ["AAPL", "AAPL", "AAPL"],
            "date": ["2024-01-02", "2024-01-02", "2024-01-03"],  # ì¤‘ë³µ
            "open": [100.0, 101.0, 102.0],
            "high": [105.0, 106.0, 108.0],
            "low": [98.0, 99.0, 100.0],
            "close": [103.0, 104.0, 106.0],
            "volume": [1000000, 1100000, 1200000],
        })
        df.to_parquet(daily_dir / "all_daily.parquet", index=False)

        # Apply ì‹¤í–‰
        repairer = DataRepairer(
            temp_parquet_dir,
            backup_dir=temp_parquet_dir / "backup",
            dry_run=False,
        )
        removed = repairer.remove_duplicates_daily()

        # ì¤‘ë³µ ì œê±° í™•ì¸
        assert removed == 1
        result_df = pd.read_parquet(daily_dir / "all_daily.parquet")
        assert len(result_df) == 2  # ì¤‘ë³µ ì œê±°ë¨
