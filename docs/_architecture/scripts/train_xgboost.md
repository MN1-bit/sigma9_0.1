# train_xgboost.py

## ê¸°ë³¸ ì •ë³´
| í•­ëª© | ê°’ |
|------|---|
| **ê²½ë¡œ** | `scripts/train_xgboost.py` |
| **ì—­í• ** | R-4 Phase E Step 3: XGBoost ë¶„ë¥˜ê¸° í•™ìŠµ + SHAP ê¸°ë°˜ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ |
| **ë¼ì¸ ìˆ˜** | 341 |

## í•¨ìˆ˜

### `load_and_merge_features`
| êµ¬ë¶„ | ì‹œê·¸ë‹ˆì²˜/ì„¤ëª… |
|------|--------------|
| **ì‹œê·¸ë‹ˆì²˜** | `() -> pd.DataFrame` |
| **ì—­í• ** | D-1 í”¼ì²˜ì™€ M-n í”¼ì²˜ ë³‘í•© (D-1 í™•ì¥ ìš°ì„ ) |

### `prepare_features`
| êµ¬ë¶„ | ì‹œê·¸ë‹ˆì²˜/ì„¤ëª… |
|------|--------------|
| **ì‹œê·¸ë‹ˆì²˜** | `(df) -> tuple[X, y, feature_cols]` |
| **ì—­í• ** | í•™ìŠµìš© í”¼ì²˜/ë¼ë²¨ ë¶„ë¦¬, ê²°ì¸¡ê°’ ì²˜ë¦¬ |

### `train_xgboost`
| êµ¬ë¶„ | ì‹œê·¸ë‹ˆì²˜/ì„¤ëª… |
|------|--------------|
| **ì‹œê·¸ë‹ˆì²˜** | `(X, y, cv_splits=5) -> tuple[model, results]` |
| **ì—­í• ** | XGBoost ë¶„ë¥˜ê¸° í•™ìŠµ + TimeSeriesSplit CV |

**ëª¨ë¸ íŒŒë¼ë¯¸í„°:**
| íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
|----------|---|------|
| `n_estimators` | 100 | íŠ¸ë¦¬ ê°œìˆ˜ |
| `max_depth` | 6 | ìµœëŒ€ ê¹Šì´ |
| `reg_alpha` | 0.1 | L1 ì •ê·œí™” |
| `reg_lambda` | 1.0 | L2 ì •ê·œí™” |

### `analyze_shap`
| êµ¬ë¶„ | ì‹œê·¸ë‹ˆì²˜/ì„¤ëª… |
|------|--------------|
| **ì‹œê·¸ë‹ˆì²˜** | `(model, X, top_k=30) -> pd.DataFrame` |
| **ì—­í• ** | SHAP ë¶„ì„ìœ¼ë¡œ í”¼ì²˜ ì¤‘ìš”ë„ ë­í‚¹ ì¶”ì¶œ |

## ğŸ”— ì™¸ë¶€ ì—°ê²° (Connections)

### Data In
| ì†ŒìŠ¤ | ë°ì´í„° |
|------|--------|
| `scripts/d1_features_extended.parquet` | D-1 í™•ì¥ í”¼ì²˜ |
| `scripts/m_n_features.parquet` | M-n ë¶„ë´‰ í”¼ì²˜ |

### Data Out
| ëŒ€ìƒ | ì„¤ëª… |
|------|------|
| `scripts/feature_importance.csv` | SHAP ê¸°ë°˜ í”¼ì²˜ ë­í‚¹ |
| `scripts/shap_summary.png` | SHAP Summary Plot |
| `scripts/ml_report.json` | CV ì ìˆ˜, AUC, íŒŒë¼ë¯¸í„° |

### Data Flow
```mermaid
graph LR
    A["d1_features_extended.parquet"] --> B["train_xgboost.py"]
    C["m_n_features.parquet"] --> B
    B --> D["feature_importance.csv"]
    B --> E["shap_summary.png"]
    B --> F["ml_report.json"]
```

## ì™¸ë¶€ ì˜ì¡´ì„±
- `xgboost`
- `shap`
- `sklearn`
- `pandas`, `numpy`
- `matplotlib`
