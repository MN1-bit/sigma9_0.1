# 급등 전 스캐닝 전략: 방법론 토론

> **문서 번호**: 001-01 부속 토론  
> **작성일**: 2026-01-15  
> **대상 문서**: [_detection.md](./_detection.md)  
> **대주제**: ML 기반 vs 로깅→LLM 기반 접근법 선택

---

## 등장인물

| 역할 | 이름 | 배경 |
|------|------|------|
| **백엔드 개발자** | 민수 | Python/시스템 아키텍처 전문, 운영 안정성 중시 |
| **ML 엔지니어** | 지현 | 시계열 예측/분류 모델 경험, 모델 해석성 연구 |
| **퀀트 애널리스트** | 현우 | 통계적 차익거래, 팩터 모델 설계 경력 |
| **단타 트레이더** | 성민 | 10년차 데이트레이더, 테이프 리딩/경험적 패턴 |
| **금융공학 리서처** | 수진 | 기관 알고트레이딩팀 출신, 리스크 관리 전문 |

---

## 1라운드: 핵심 질문 — ML이냐 LLM이냐

### 🎯 민수 (개발자)

> 운영 관점에서 질문드립니다. **두 접근법의 핵심 차이**가 뭔가요?

---

### 🤖 지현 (ML 엔지니어)

둘 다 "급등 전 종목 탐지"가 목표지만, 접근이 완전히 다릅니다.

| 구분 | ML 기반 | 로깅→LLM 기반 |
|------|---------|---------------|
| 입력 | 정형화된 지표 벡터 (RVOL, Gap, ATR 등) | 자연어화된 지표 로그 텍스트 |
| 학습 | 과거 Daygainer 라벨로 분류기 훈련 | 프롬프트 엔지니어링 + Few-shot |
| 추론 | 밀리초 단위 | 수 초 (API 호출) |
| 비용 | 초기 학습 비용, 추론은 무료 | 호출당 토큰 비용 |
| 해석성 | Feature Importance, SHAP 등 | 추론 과정 텍스트로 설명 |

---

### 📊 현우 (퀀트)

솔직히 말씀드리면, **퀀트 관점에서 ML이 표준**입니다. 

이유:
1. **통계적 검증 가능** — P-value, Cross-Validation으로 과적합 체크
2. **재현성** — 동일 입력 → 동일 출력 보장
3. **백테스트 친화적** — 과거 데이터로 수천 번 시뮬레이션 가능

LLM은 "똑같은 질문에 다른 답" 문제가 있어요. 백테스트에서 치명적입니다.

---

### 💹 성민 (단타 트레이더)

잠깐요, 저는 좀 다르게 봅니다.

실전에서 급등 전 패턴은 **숫자로 못 잡는 게 많아요**:
- "거래량은 평범한데 체결 속도가 빨라짐"
- "호가창 매도벽이 허술해 보임"
- "뉴스 헤드라인 뉘앙스"

이런 건 숫자 피처로 만들기 어렵고, 오히려 **맥락을 이해하는 LLM**이 유리할 수 있어요.

---

### 🏦 수진 (금융공학)

두 분 다 맞는 말씀이에요. 하지만 **기관 리스크 관점**에서 몇 가지 짚겠습니다:

1. **모델 거버넌스**: 규제 환경에서 "왜 이 종목을 선택했나" 설명 필요
   - ML: Feature Importance로 설명 가능하나 복잡
   - LLM: 추론 과정 텍스트가 오히려 직관적일 수 있음

2. **오류 모드**: 
   - ML: Silent Failure — 틀려도 확신 있게 답함
   - LLM: Hallucination — 없는 사실 생성

3. **비용 스케일링**: 하루 수천 종목 스캔 시
   - ML: 거의 무료 (추론만)
   - LLM: 토큰 비용 급증 (종목당 $0.01 × 5000 = $50/일?)

---

## 2라운드: 실제 구현 시나리오

### 🎯 민수 (개발자)

구체적으로 **두 시나리오를 그려보면**:

#### 시나리오 A: ML 기반
```
[매일 장 마감 후]
1. 전체 종목 → D-1 지표 계산 (RVOL, Gap, ATR, 이평선 등)
2. 지표 벡터 → 학습된 분류기 입력
3. 출력: 급등 확률 스코어 (0~1)
4. 상위 N개 → 다음날 모니터링 리스트

추론 시간: 전체 5000종목 < 1분
```

#### 시나리오 B: 로깅→LLM 기반
```
[매일 장 마감 후]
1. 전체 종목 → D-1 지표 계산
2. 지표를 자연어 로그로 변환:
   "AAPL: RVOL 2.3 (평균대비 2.3배), Gap +3.2%, 
    5일선 돌파, 20일선 위, ATR 확대 중..."
3. LLM에 프롬프트: "다음 중 급등 가능성 높은 종목 10개 선정하고 이유 설명"
4. LLM 응답 파싱 → 모니터링 리스트

추론 시간: 종목당 2초 × 5000 = 2.7시간 (병렬화 필요)
```

---

### 🤖 지현 (ML 엔지니어)

시나리오 B의 문제점 몇 가지:

1. **전체 종목을 LLM에?** — 컨텍스트 제한 (128K 토큰이어도 한계)
2. **배치 처리 불가** — 순차 호출 필요
3. **결과 파싱 불안정** — JSON 출력 강제해도 가끔 깨짐

그래서 **하이브리드**가 현실적입니다:
```
[2단계 파이프라인]
Stage 1 (ML): 5000종목 → 상위 100개 필터링 (< 1분)
Stage 2 (LLM): 100개에 대해 심층 분석 (< 5분)
```

---

### 📊 현우 (퀀트)

> 하이브리드 동의합니다. 하지만 **LLM 단계가 꼭 필요한가?**

ML 모델의 Feature Importance 상위 요인만 로깅해도 충분히 해석 가능합니다:
```
종목: NVDA
급등 확률: 0.82
주요 요인:
  - RVOL: 3.1 (기여도 32%)
  - Gap: +4.2% (기여도 28%)
  - 20일선 돌파 (기여도 18%)
```

LLM을 쓰면 **인간이 읽기 편한 문장**으로 변환할 수 있지만, 그게 의사결정을 바꾸진 않아요.

---

### 💹 성민 (단타 트레이더)

제가 LLM에 기대하는 건 **숫자 외의 맥락**이에요:

예를 들어:
- "최근 섹터 전체가 강세인데 이 종목만 눌림목"
- "실적 발표 D-2, 과거 실적 서프라이즈 패턴"
- "CEO 트윗 후 첫 장"

이런 건 숫자 피처로 안 되고, 뉴스/이벤트 텍스트가 필요합니다.

---

### 🏦 수진 (금융공학)

성민 님 말씀이 핵심을 찔렀어요.

**구조화 데이터 vs 비구조화 데이터** 문제입니다:

| 데이터 유형 | 예시 | 적합 도구 |
|-------------|------|-----------|
| 구조화 | OHLCV, 지표, 재무제표 | ML |
| 비구조화 | 뉴스 헤드라인, SEC 공시, 소셜 | NLP/LLM |

**제안**: 
- Stage 1 (ML): 구조화 데이터로 1차 필터
- Stage 2 (LLM): 비구조화 데이터로 맥락 분석

이렇게 하면 LLM은 **100개 이하**만 처리하므로 비용/시간 합리적.

---

## 3라운드: 하이브리드 아키텍처 합의

### 🎯 민수 (개발자)

그럼 **하이브리드로 가는 게 맞는 것 같은데**, 아키텍처를 구체화해볼까요?

```
┌─────────────────────────────────────────────────────────────────┐
│                    Pre-Surge Detection Pipeline                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────┐    ┌─────────────────┐    ┌─────────────────┐ │
│  │ Data Layer │───▶│   Stage 1: ML   │───▶│  Stage 2: LLM   │ │
│  └─────────────┘    └─────────────────┘    └─────────────────┘ │
│        │                    │                      │           │
│        ▼                    ▼                      ▼           │
│  ┌───────────┐       ┌───────────┐          ┌───────────┐     │
│  │ Parquet   │       │ 5000→100  │          │  100→Top20│     │
│  │ + 뉴스 DB │       │ (< 1min)  │          │  (< 5min) │     │
│  └───────────┘       └───────────┘          └───────────┘     │
│                                                    │           │
│                                                    ▼           │
│                                             ┌───────────┐     │
│                                             │ 워치리스트 │     │
│                                             │ + 설명    │     │
│                                             └───────────┘     │
└─────────────────────────────────────────────────────────────────┘
```

---

### 🤖 지현 (ML 엔지니어)

Stage 1 (ML) 상세 설계:

```python
# 입력 피처 (예시)
features = [
    'rvol_5d',           # 5일 평균 대비 거래량
    'gap_pct',           # 시가 갭 %
    'atr_expansion',     # ATR 확대율
    'ma_crossover_5_20', # 5/20일선 크로스오버
    'rsi_14',            # RSI(14)
    'distance_from_52w_high',  # 52주 고점 대비 거리
    'sector_momentum',   # 섹터 모멘텀
    'float_turnover',    # 유통주식 회전율
]

# 모델 후보
models = [
    'XGBoost',           # 기본, 해석성 좋음
    'LightGBM',          # 대용량 빠름
    'TabNet',            # 딥러닝 기반, Attention 해석
]

# 출력
output = pd.DataFrame({
    'ticker': [...],
    'surge_probability': [...],  # 0~1
    'top_features': [...],       # 기여도 상위 3개
})
```

---

### 🏦 수진 (금융공학)

Stage 2 (LLM) 프롬프트 설계:

```
[System]
당신은 데이 트레이딩 전문가입니다. 
주어진 종목의 기술적 지표와 뉴스를 분석하여 
내일 급등 가능성을 평가하세요.

[User]
## 종목: {ticker}

### 기술적 지표 (D-1 기준)
- RVOL: {rvol} (5일 평균 대비)
- Gap: {gap}%
- ATR 변화: {atr_change}
- 이평선 상태: {ma_status}

### 최근 뉴스/이벤트
{news_summary}

### ML 모델 예측
- 급등 확률: {ml_score}
- 주요 요인: {top_features}

---
위 정보를 바탕으로:
1. 급등 가능성 (상/중/하)
2. 핵심 근거 2-3가지
3. 주의할 리스크 1-2가지
```

---

### 📊 현우 (퀀트)

**백테스트 전략**도 정해야 합니다:

| 검증 방식 | ML Stage | LLM Stage |
|-----------|----------|-----------|
| Cross-Validation | 5-Fold Time-Series CV | N/A (비결정적) |
| Out-of-Sample | 최근 3개월 홀드아웃 | 샘플 수동 검증 |
| Walk-Forward | 월별 재학습 | 프롬프트 버전 관리 |

> [!WARNING]
> LLM은 동일 입력에 다른 출력을 주므로, **정성적 검증**만 가능합니다.  
> 최종 의사결정은 ML 스코어에 의존하고, LLM은 **보조 해석** 용도로 제한하세요.

---

### 💹 성민 (단타 트레이더)

현실적으로 **첫 버전은 ML만으로 시작**하고, LLM은 나중에 붙이는 게 어때요?

이유:
1. ML 파이프라인만으로도 충분히 복잡
2. LLM 없이도 Feature Importance로 해석 가능
3. LLM 비용/지연 이슈 해결 후 추가

**로드맵 제안**:
- v0.1: ML Only (XGBoost + SHAP)
- v0.2: 뉴스 피처 추가 (Sentiment Score)
- v0.3: LLM 통합 (Top 20 종목 심층 분석)

---

## 4라운드: 합의 및 결론

### 🎯 민수 (개발자)

정리하면:

| 결정 사항 | 합의 내용 |
|-----------|-----------|
| 주 접근법 | **하이브리드** (ML 1차 → LLM 2차) |
| 초기 버전 | ML Only로 시작 (v0.1) |
| ML 모델 | XGBoost 기본, TabNet 실험 |
| LLM 역할 | 보조 해석 (의사결정 주체 아님) |
| 비용 관리 | LLM은 Top 100 이하에만 적용 |

---

### 🏦 수진 (금융공학)

**리스크 관리 원칙** 추가:

1. **ML 스코어 임계값**: 0.7 이상만 워치리스트 진입
2. **LLM 거부권**: "리스크 높음" 판정 시 제외
3. **사람 최종 승인**: 자동 매매 아님, 스캔 보조 도구

---

### 🤖 지현 (ML 엔지니어)

**기술 스택 확정**:

```yaml
Stage 1 (ML):
  library: scikit-learn, xgboost, shap
  storage: Parquet (기존)
  compute: 로컬 Python

Stage 2 (LLM):  # v0.3+
  provider: OpenAI / Claude
  model: gpt-4o-mini (비용 효율)
  fallback: 로컬 LLaMA (오프라인)
```

---

### 📊 현우 (퀀트)

**성과 측정 지표**:

| 지표 | 정의 | 목표 |
|------|------|------|
| Precision@20 | 상위 20개 중 실제 급등 비율 | > 30% |
| Recall | 전체 급등주 중 탐지 비율 | > 50% |
| Lead Time | 급등 전 얼마나 먼저 탐지했나 | D-1 이상 |

---

## 5라운드: 미해결 이슈

| 이슈 | 담당 | 상태 |
|------|------|------|
| Daygainer 정의 (몇 % 이상?) | 현우 | 🔲 TBD |
| 뉴스 데이터 소스 (Polygon? 별도?) | 민수 | 🔲 TBD |
| LLM API 예산 | 전체 | 🔲 TBD |
| 모델 재학습 주기 | 지현 | 🔲 TBD |

---

## 결론

> [!IMPORTANT]
> **최종 합의: 하이브리드 접근법 (ML 주력 + LLM 보조)**
> 
> - **v0.1**: ML Only (XGBoost + SHAP 해석)
> - **v0.2**: 뉴스 Sentiment 피처 추가
> - **v0.3**: LLM 통합 (Top N 심층 분석)
> 
> LLM은 의사결정 주체가 아닌 **해석 보조 도구**로 제한합니다.

---

**문서 이력**
| 버전 | 일자 | 변경 내용 |
|------|------|----------|
| 1.0 | 2026-01-15 | 초안 작성 |
