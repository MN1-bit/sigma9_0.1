# 3-Stage ë°±í…ŒìŠ¤íŠ¸ Full êµ¬í˜„ ê³„íšì„œ

> **ì‘ì„±ì¼**: 2026-01-15 | **ì˜ˆìƒ**: 16h (Phase 1~4)  
> **ê¸°ë°˜**: [reflect01.md](./reflect/reflect01.md), [reflect02.md](./reflect/reflect02.md), [005-01_3stage_impl_plan.md](./005-01_3stage_impl_plan.md)  
> **ìƒíƒœ**: ğŸ“‹ Full Plan (ê°œë°œ ê°€ëŠ¥ ìƒíƒœ)

---

## 1. ëª©í‘œ

**3-Stage íŒŒì´í”„ë¼ì¸ êµ¬í˜„:**
- **Stage 0**: D-1 Attempt Scanner (`has_attempt` ì˜ˆì¸¡)
- **Stage 1**: Success vs Fail Classifier (`is_success` ì˜ˆì¸¡)
- **Stage 2**: Alert Policy (ìš´ì˜ ìµœì í™”)

### 1.1 í•µì‹¬ ì„±ê³¼ ì§€í‘œ (KPI)

| ì§€í‘œ | Stage | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|-------|------|----------|
| **Recall@200** | 0 | â‰¥ 70% | ì¼ë³„ Top-200 ë‚´ Attempt ì¢…ëª© ë¹„ìœ¨ í‰ê·  |
| **Candidates/day** | 0 | 150-250 | ì¼ë³„ í›„ë³´ ìˆ˜ ë¶„í¬ |
| **Alerts/day** | 1 | 20-50 | ì¼ë³„ í‰ê·  ì•Œë¦¼ ìˆ˜ |
| **Success Rate** | 1 | â‰¥ 50% | Alerts ì¤‘ Daygainer ë¹„ìœ¨ |
| **Lead Time** | 1 | â‰¥ 15min | T0 - Alert ì‹œê°„ í‰ê·  |

---

## 2. ë ˆì´ì–´ ì²´í¬

> **ì°¸ì¡°**: [REFACTORING.md](../../refactor/REFACTORING.md)

- [x] ë ˆì´ì–´ ê·œì¹™ ìœ„ë°˜ ì—†ìŒ (ë…ë¦½ ìŠ¤í¬ë¦½íŠ¸ â€” `scripts/` í´ë”)
- [x] ìˆœí™˜ ì˜ì¡´ì„± ì—†ìŒ (ë¶„ì„ìš© ìŠ¤í¬ë¦½íŠ¸, ë³„ë„ í”„ë¡œì„¸ìŠ¤)
- [x] DI Container ë“±ë¡ í•„ìš”: **ì•„ë‹ˆì˜¤** (ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì•„ë‹˜)

---

## 3. ê¸°ì¡´ ì†”ë£¨ì…˜ ê²€ìƒ‰ ê²°ê³¼

| ì†”ë£¨ì…˜ | ì¶œì²˜ | ì±„íƒ ì—¬ë¶€ | ì‚¬ìœ  |
|--------|------|----------|------|
| **pandas-ta** | PyPI | âœ… ìœ ì§€ | 130+ ì§€í‘œ, CCI ê°œë³„ ê²€ì¦ í•„ìš” |
| **XGBoost** | PyPI | âœ… ìœ ì§€ | ë¶„ë¥˜ê¸° + L1/L2 ì •ê·œí™” |
| **SHAP** | PyPI | âœ… ìœ ì§€ | í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ |
| **Polars** | PyPI | âœ… ì±„íƒ | ëŒ€ìš©ëŸ‰ ë¶„ë´‰ ì²˜ë¦¬ (pandas ëŒ€ë¹„ 10x ë¹ ë¦„) |
| **imodels (RuleFit)** | PyPI | ğŸ†• ì±„íƒ | í•´ì„ ê°€ëŠ¥í•œ ë£° ì¶”ì¶œ |
| **scikit-learn** | PyPI | âœ… ìœ ì§€ | GroupKFold, ì „ì²˜ë¦¬ |
| **DuckDB** | PyPI | â¸ï¸ ëŒ€ê¸° | í•„ìš”ì‹œ ì¡°ì¸ ìµœì í™” |

---

## 4. í•µì‹¬ ì •ì˜

### 4.1 Attempt Trigger (Stage 0 íƒ€ê¹ƒ)

ë¶„ë´‰ tì—ì„œ ì•„ë˜ ì¡°ê±´ ì¶©ì¡± ì‹œ **Attempt ì´ë²¤íŠ¸** ìƒì„±:

```python
minute_rvol(t) >= 3.0  # ë™ì¼ minute-of-day 20ì¼ í‰ê·  ëŒ€ë¹„
AND (
    ret_5m(t) >= +1.5%       # 5ë¶„ ìˆ˜ìµë¥ 
    OR breakout_flag(t)      # 60ë¶„ ë°•ìŠ¤ ìƒë‹¨ ëŒíŒŒ
)
```

**ìƒì„¸ íŒŒë¼ë¯¸í„°:**

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |
|----------|--------|------|------|
| `RVOL_TRIG` | 3.0 | 2.0~5.0 | ë¶„ë‹¹ RVOL ì„ê³„ê°’ |
| `P_TRIG` | 1.5% | 1.0%~3.0% | 5ë¶„ ìˆ˜ìµë¥  ì„ê³„ê°’ |
| `BREAKOUT_WINDOW` | 60 | 30~120 | ë°•ìŠ¤ ëŒíŒŒ ìœˆë„ìš° (ë¶„) |
| `COOLDOWN` | 30 | 15~60 | ì—°ì† Attempt ìµœì†Œ ê°„ê²© (ë¶„) |

### 4.2 Failed Pump (Stage 1 ìŒì„±)

```python
has_attempt = 1
AND is_daygainer = 0
AND drawdown_from_hod >= 30%  # HOD ì´í›„ ìµœëŒ€ ë“œë¡œë‹¤ìš´
```

### 4.3 Daygainer (ìµœì¢… ë¼ë²¨)

```python
oc_return = (close - open) / open >= 0.75  # +75% ì´ìƒ
AND dollar_volume >= 500_000              # $50ë§Œ ì´ìƒ
AND price >= 0.10                         # $0.1 ì´ìƒ
```

---

## 5. ë°ì´í„° ìŠ¤í‚¤ë§ˆ

### 5.1 ì¶œë ¥ íŒŒì¼ ëª©ë¡

| íŒŒì¼ | ì„¤ëª… | PK | ì˜ˆìƒ í¬ê¸° |
|------|------|-----|----------|
| `data/backtest/ref_minute_volume_profile.parquet` | minute-of-dayë³„ ê¸°ëŒ€ ê±°ë˜ëŸ‰ | `(symbol, asof_date, minute_of_day)` | ~50MB |
| `data/backtest/event_attempt.parquet` | Attempt ì´ë²¤íŠ¸ í…Œì´ë¸” | `(symbol, trade_date, attempt_id)` | ~5MB |
| `data/backtest/label_attempt_outcome.parquet` | Attempt ì„±ê³µ/ì‹¤íŒ¨ ë¼ë²¨ | `(symbol, trade_date, attempt_id)` | ~1MB |
| `data/backtest/feat_d1_asof.parquet` | Stage 0ìš© D-1 í”¼ì²˜ | `(symbol, trade_date)` | ~100MB |
| `data/backtest/feat_intraday_at_attempt.parquet` | Stage 1ìš© ë¶„ë´‰ í”¼ì²˜ | `(symbol, trade_date, attempt_id)` | ~20MB |
| `data/backtest/ml_stage0_examples.parquet` | Stage 0 í•™ìŠµ ë°ì´í„° | `(symbol, trade_date)` | ~150MB |
| `data/backtest/ml_stage1_examples.parquet` | Stage 1 í•™ìŠµ ë°ì´í„° | `(symbol, trade_date, attempt_id)` | ~30MB |

### 5.2 ì°¸ì¡° í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ

#### `ref_minute_volume_profile`

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `symbol` | STRING | í‹°ì»¤ |
| `asof_date` | DATE | ì´ ë‚ ì§œ **ì´ì „** 20ê±°ë˜ì¼ë¡œ ê³„ì‚° |
| `minute_of_day` | INT16 | 0~389 (ë¯¸êµ­ ì •ê·œì¥ 390ë¶„) |
| `exp_volume_20d` | FLOAT64 | ê¸°ëŒ€ ê±°ë˜ëŸ‰ (ì¤‘ì•™ê°’) |
| `exp_volume_std_20d` | FLOAT64 | í‘œì¤€í¸ì°¨ |

#### `event_attempt`

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `symbol` | STRING | í‹°ì»¤ |
| `trade_date` | DATE | ê±°ë˜ì¼ |
| `attempt_id` | INT8 | 1, 2, â€¦ (ê¸°ë³¸: 1ë§Œ ì‚¬ìš©) |
| `t_attempt` | DATETIME | Attempt trigger ì‹œì  |
| `trig_minute_rvol` | FLOAT64 | íŠ¸ë¦¬ê±° ë‹¹ì‹œ minute_rvol |
| `trig_ret_5m` | FLOAT64 | íŠ¸ë¦¬ê±° ë‹¹ì‹œ 5ë¶„ ìˆ˜ìµë¥  |
| `trig_breakout_flag` | BOOL | ë°•ìŠ¤ ëŒíŒŒ ì—¬ë¶€ |
| `minute_of_day` | INT16 | Attempt ë°œìƒ ì‹œê°„ (ë¶„) |

#### `label_attempt_outcome`

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `symbol` | STRING | í‹°ì»¤ |
| `trade_date` | DATE | ê±°ë˜ì¼ |
| `attempt_id` | INT8 | FK to event_attempt |
| `is_daygainer` | BOOL | Daygainer ì—¬ë¶€ |
| `is_success` | BOOL | = is_daygainer |
| `is_failed_pump` | BOOL | Failed Pump ì—¬ë¶€ |
| `hod_after_attempt` | FLOAT64 | Attempt ì´í›„ ë‹¹ì¼ ê³ ì  |
| `max_drawdown_pct` | FLOAT64 | HOD ëŒ€ë¹„ ìµœëŒ€ ë“œë¡œë‹¤ìš´ % |

---

## 6. ë³€ê²½/ìƒì„± íŒŒì¼

| íŒŒì¼ | ìœ í˜• | ì˜ˆìƒ ë¼ì¸ | ì„¤ëª… |
|------|-----|----------|------|
| `scripts/backtest/build_minute_volume_profile.py` | [NEW] | ~150 | minute-of-dayë³„ ê¸°ëŒ€ ê±°ë˜ëŸ‰ ê³„ì‚° |
| `scripts/backtest/detect_attempt.py` | [NEW] | ~250 | Attempt Trigger íƒì§€ |
| `scripts/backtest/label_attempt_outcome.py` | [NEW] | ~120 | Success/Failed Pump ë¼ë²¨ë§ |
| `scripts/backtest/build_d1_features_v2.py` | [NEW] | ~350 | D-1 í”¼ì²˜ (pandas_ta 130ê°œ + ê´´ë¦¬) |
| `scripts/backtest/build_attempt_features.py` | [NEW] | ~300 | t_attempt ì§ì „ ë¶„ë´‰ í”¼ì²˜ |
| `scripts/backtest/train_stage0.py` | [NEW] | ~250 | Stage 0 í•™ìŠµ (has_attempt) |
| `scripts/backtest/train_stage1.py` | [NEW] | ~250 | Stage 1 í•™ìŠµ (is_success) |
| `scripts/backtest/evaluate_recall_at_n.py` | [NEW] | ~200 | ì¼ë³„ Recall@N í‰ê°€ |
| `scripts/backtest/utils.py` | [NEW] | ~100 | ê³µí†µ ìœ í‹¸ë¦¬í‹° |
| `scripts/backtest/__init__.py` | [NEW] | ~10 | íŒ¨í‚¤ì§€ ì´ˆê¸°í™” |

**ì´ ì˜ˆìƒ**: ~1,980ì¤„ (10ê°œ íŒŒì¼)

---

## 7. ì‹¤í–‰ ë‹¨ê³„

### Phase 1: ë°ì´í„° ì •ë¹„ (~4h)

#### Step 1.1: í´ë” êµ¬ì¡° ìƒì„±

```bash
mkdir -p scripts/backtest
mkdir -p data/backtest
```

#### Step 1.2: minute_volume_profile ìƒì„±

**íŒŒì¼**: `scripts/backtest/build_minute_volume_profile.py`

**ì…ë ¥**:
- `data/parquet/intraday/1m/{SYMBOL}.parquet` (ë¶„ë´‰ ë°ì´í„°)

**ì²˜ë¦¬ ë¡œì§**:
```python
def build_volume_profile(symbol: str, asof_date: date) -> pl.DataFrame:
    """
    1. asof_date ì´ì „ 20ê±°ë˜ì¼ ë¶„ë´‰ ë¡œë“œ
    2. minute_of_day = (ts - 09:30) // 1ë¶„ ê³„ì‚°
    3. (symbol, minute_of_day) ê·¸ë£¹ë³„ volume ì¤‘ì•™ê°’/std ê³„ì‚°
    4. ê²°ê³¼ ì €ì¥
    """
    # í¬ì¸íŠ¸-ì¸-íƒ€ì„ ê°•ì œ: asof_date ì´ì „ë§Œ ì‚¬ìš©
    minute_df = load_minute_bars(symbol, start=asof_date - 30, end=asof_date - 1)
    
    # ìµœê·¼ 20ê±°ë˜ì¼ë§Œ í•„í„°
    trading_days = minute_df.select("trade_date").unique().sort().tail(20)
    minute_df = minute_df.filter(pl.col("trade_date").is_in(trading_days))
    
    # minute_of_day ê³„ì‚° (09:30 = 0, 09:31 = 1, ...)
    minute_df = minute_df.with_columns([
        ((pl.col("ts").dt.hour() - 9) * 60 + pl.col("ts").dt.minute() - 30)
        .alias("minute_of_day")
    ])
    
    # ì§‘ê³„
    profile = minute_df.group_by("minute_of_day").agg([
        pl.col("volume").median().alias("exp_volume_20d"),
        pl.col("volume").std().alias("exp_volume_std_20d")
    ])
    
    return profile.with_columns([
        pl.lit(symbol).alias("symbol"),
        pl.lit(asof_date).alias("asof_date")
    ])
```

**ì¶œë ¥**: `data/backtest/ref_minute_volume_profile.parquet`

**ê²€ì¦**:
```python
assert profile["minute_of_day"].min() >= 0
assert profile["minute_of_day"].max() <= 389
assert profile["exp_volume_20d"].null_count() == 0
```

---

#### Step 1.3: Attempt íƒì§€

**íŒŒì¼**: `scripts/backtest/detect_attempt.py`

**ì…ë ¥**:
- `data/parquet/intraday/1m/{SYMBOL}.parquet` (ë¶„ë´‰)
- `data/backtest/ref_minute_volume_profile.parquet` (ê¸°ëŒ€ ê±°ë˜ëŸ‰)
- `scripts/control_groups.csv` (ëŒ€ìƒ ì‹¬ë³¼)

**ì²˜ë¦¬ ë¡œì§**:
```python
# íŒŒë¼ë¯¸í„° (configë¡œ ì™¸ë¶€í™”)
RVOL_TRIG = 3.0
P_TRIG = 0.015  # 1.5%
BREAKOUT_WINDOW = 60
COOLDOWN_MINUTES = 30

def detect_attempt(symbol: str, trade_date: date) -> list[dict]:
    """
    1. í•´ë‹¹ ì¼ì ë¶„ë´‰ ë¡œë“œ
    2. minute_rvol = volume / exp_volume_20d
    3. ret_5m = (close - close.shift(5)) / close.shift(5)
    4. breakout_flag = close > rolling_max(close, 60).shift(1)
    5. íŠ¸ë¦¬ê±° ì¡°ê±´ ì¶©ì¡± ë¶„ë´‰ íƒì§€
    6. ì²« Attemptë§Œ ì €ì¥ (or COOLDOWN ì ìš©)
    """
    # ë¶„ë´‰ ë¡œë“œ
    minute_df = load_minute_bars(symbol, trade_date)
    
    # ê¸°ëŒ€ ê±°ë˜ëŸ‰ ì¡°ì¸ (asof_date = trade_date ê¸°ì¤€)
    profile = load_volume_profile(symbol, asof_date=trade_date)
    minute_df = minute_df.join(profile, on="minute_of_day", how="left")
    
    # minute_rvol ê³„ì‚°
    minute_df = minute_df.with_columns([
        (pl.col("volume") / pl.col("exp_volume_20d")).alias("minute_rvol")
    ])
    
    # ret_5m ê³„ì‚°
    minute_df = minute_df.with_columns([
        ((pl.col("close") - pl.col("close").shift(5)) / pl.col("close").shift(5))
        .alias("ret_5m")
    ])
    
    # breakout_flag ê³„ì‚°
    minute_df = minute_df.with_columns([
        (pl.col("close") > pl.col("close").rolling_max(BREAKOUT_WINDOW).shift(1))
        .alias("breakout_flag")
    ])
    
    # íŠ¸ë¦¬ê±° ì¡°ê±´
    trigger_mask = (
        (pl.col("minute_rvol") >= RVOL_TRIG) &
        ((pl.col("ret_5m") >= P_TRIG) | (pl.col("breakout_flag")))
    )
    
    triggers = minute_df.filter(trigger_mask)
    
    # í•˜ë£¨ ì²« Attemptë§Œ (or COOLDOWN ì ìš©)
    if len(triggers) == 0:
        return []
    
    first_attempt = triggers.sort("ts").head(1)
    return first_attempt.to_dicts()
```

**ì¶œë ¥**: `data/backtest/event_attempt.parquet`

**ì»¬ëŸ¼**:
```
symbol, trade_date, attempt_id, t_attempt, 
trig_minute_rvol, trig_ret_5m, trig_breakout_flag, minute_of_day
```

---

#### Step 1.4: Attempt ë¼ë²¨ë§

**íŒŒì¼**: `scripts/backtest/label_attempt_outcome.py`

**ì…ë ¥**:
- `data/backtest/event_attempt.parquet`
- `data/parquet/intraday/1m/{SYMBOL}.parquet` (ë¶„ë´‰)
- `scripts/control_groups.csv` (is_daygainer ì»¬ëŸ¼)

**ì²˜ë¦¬ ë¡œì§**:
```python
def label_outcome(symbol: str, trade_date: date, t_attempt: datetime) -> dict:
    """
    1. t_attempt ì´í›„ ë¶„ë´‰ ë¡œë“œ
    2. HOD_after_attempt = max(high) after t_attempt
    3. ì¢…ê°€ ë˜ëŠ” 15:30 ê°€ê²© í™•ì¸
    4. drawdown = (HOD - close) / HOD
    5. is_failed_pump = drawdown >= 0.30 AND not is_daygainer
    """
    # Attempt ì´í›„ ë¶„ë´‰
    after_df = load_minute_bars(symbol, trade_date, after=t_attempt)
    
    hod_after = after_df["high"].max()
    final_close = after_df.sort("ts").tail(1)["close"].item()
    
    drawdown = (hod_after - final_close) / hod_after if hod_after > 0 else 0
    
    # ì™¸ë¶€ì—ì„œ is_daygainer ê°€ì ¸ì˜´
    is_daygainer = get_daygainer_label(symbol, trade_date)
    
    return {
        "is_daygainer": is_daygainer,
        "is_success": is_daygainer,
        "is_failed_pump": (drawdown >= 0.30) and not is_daygainer,
        "hod_after_attempt": hod_after,
        "max_drawdown_pct": drawdown
    }
```

**ì¶œë ¥**: `data/backtest/label_attempt_outcome.parquet`

---

### Phase 2: Stage 0 êµ¬í˜„ (~4h)

#### Step 2.1: D-1 í”¼ì²˜ ìƒì„± (v2)

**íŒŒì¼**: `scripts/backtest/build_d1_features_v2.py`

**ê¸°ì¡´ ì½”ë“œ ì°¸ì¡°**: `scripts/build_d1_features.py` (í™•ì¥)

**ì…ë ¥**:
- `data/parquet/daily/all_daily.parquet` (ì¼ë´‰)
- `scripts/control_groups.csv` (ëŒ€ìƒ ì‹¬ë³¼/ë‚ ì§œ)

**í”¼ì²˜ ëª©ë¡** (ì´ ~150ê°œ):

##### A. pandas_ta 130ê°œ ì§€í‘œ

```python
import pandas_ta as ta

# ì „ëµ ê¸°ë°˜ ì „ì²´ ì§€í‘œ ê³„ì‚°
df.ta.strategy("all")  # 130+ ì§€í‘œ

# CCI ì´ìƒì¹˜ ê²€ì¦
df = df.with_columns([
    pl.when(pl.col("CCI_20").abs() > 1000)
    .then(None)
    .otherwise(pl.col("CCI_20"))
    .alias("CCI_20_validated")
])
```

##### B. ê´´ë¦¬ í”¼ì²˜ (Divergence)

| í”¼ì²˜ëª… | ê³„ì‚°ì‹ | ìš©ë„ |
|--------|--------|------|
| `rsi_5_14_div` | RSI_5 - RSI_14 | ë‹¨ê¸° ê³¼ì—´ + ì¤‘ê¸° ì—¬ë ¥ |
| `macd_signal_div` | MACD - Signal | ì¶”ì„¸ ë¶„ê¸°ì  |
| `sma_5_20_div` | SMA_5 / SMA_20 - 1 | ì´í‰ì„  ì´ê²©ë„ |
| `close_vs_ma20` | close / SMA_20 - 1 | ê°€ê²© ë ˆë²¨ |
| `bb_width_pctile` | BB_width 20ì¼ ë°±ë¶„ìœ„ | ë³€ë™ì„± ìˆ˜ì¶• |

##### C. êµ¬ì¡°ì  í”¼ì²˜

| í”¼ì²˜ëª… | ê³„ì‚°ì‹ | ìš©ë„ |
|--------|--------|------|
| `dist_to_20d_low` | (close - low_20d) / low_20d | ë°”ë‹¥ ì´ê²©ë„ |
| `dist_to_52w_high` | close / high_52w - 1 | ê³ ì  ëŒ€ë¹„ ìœ„ì¹˜ |
| `rvol_20d` | volume / avg_volume_20d | ê±°ë˜ëŸ‰ ì´ìƒ ì§•í›„ |
| `atr_pctile` | ATR 20ì¼ ëŒ€ë¹„ ë°±ë¶„ìœ„ | ë³€ë™ì„± ìƒíƒœ |
| `tight_range_intensity` | (high - low) / ATR | VCP íŒ¨í„´ |
| `gap_history_3d` | ìµœê·¼ 3ì¼ ê°­ í‰ê·  | ê°­ ë¹ˆë„ |

##### D. asof_date ê°•ì œ

```python
# í•µì‹¬: ëª¨ë“  í”¼ì²˜ëŠ” D-1ê¹Œì§€ë§Œ ì‚¬ìš©
def build_d1_features(symbol: str, trade_date: date) -> dict:
    asof_date = trade_date - timedelta(days=1)  # D-1
    daily_df = load_daily(symbol, end=asof_date)
    
    # pandas_ta ê³„ì‚° (D-1ê¹Œì§€ë§Œ)
    features = calculate_ta_features(daily_df)
    
    return {
        "symbol": symbol,
        "trade_date": trade_date,  # ì˜ˆì¸¡ ëŒ€ìƒ D
        "asof_date": asof_date,    # í”¼ì²˜ ê¸°ì¤€ D-1
        **features
    }
```

**ì¶œë ¥**: `data/backtest/feat_d1_asof.parquet`

---

#### Step 2.2: Stage 0 í•™ìŠµ

**íŒŒì¼**: `scripts/backtest/train_stage0.py`

**ì…ë ¥**:
- `data/backtest/feat_d1_asof.parquet`
- `data/backtest/event_attempt.parquet` (has_attempt ë¼ë²¨)

**ì²˜ë¦¬ ë¡œì§**:
```python
from sklearn.model_selection import GroupKFold
from xgboost import XGBClassifier
import shap

def train_stage0():
    # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    features = pl.read_parquet("data/backtest/feat_d1_asof.parquet")
    attempts = pl.read_parquet("data/backtest/event_attempt.parquet")
    
    # has_attempt ë¼ë²¨ ìƒì„±
    features = features.with_columns([
        pl.col("symbol").is_in(attempts["symbol"]).alias("has_attempt")
    ])
    
    # 2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  (ì‹œê³„ì—´ ê¸°ë°˜)
    train_mask = features["trade_date"] < "2025-01-01"
    train_df = features.filter(train_mask)
    test_df = features.filter(~train_mask)
    
    # 3. GroupKFold (trade_date ê·¸ë£¹)
    gkf = GroupKFold(n_splits=5)
    groups = train_df["trade_date"].to_numpy()
    
    # 4. XGBoost í•™ìŠµ
    model = XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        reg_alpha=0.1,  # L1
        reg_lambda=1.0, # L2
        scale_pos_weight=10,  # í´ë˜ìŠ¤ ë¶ˆê· í˜•
        random_state=42
    )
    
    # CV í•™ìŠµ
    for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train, y_train, groups)):
        model.fit(X_train[train_idx], y_train[train_idx])
        val_score = model.score(X_train[val_idx], y_train[val_idx])
        print(f"Fold {fold}: {val_score:.4f}")
    
    # 5. ìµœì¢… í•™ìŠµ ë° ì €ì¥
    model.fit(X_train, y_train)
    joblib.dump(model, "data/backtest/model_stage0.joblib")
    
    # 6. SHAP ë¶„ì„
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_test)
    
    return model, shap_values
```

**ì¶œë ¥**:
- `data/backtest/model_stage0.joblib`
- `data/backtest/shap_stage0.png`

---

### Phase 3: Stage 1 êµ¬í˜„ (~4h)

#### Step 3.1: Attempt í”¼ì²˜ ìƒì„±

**íŒŒì¼**: `scripts/backtest/build_attempt_features.py`

**ì…ë ¥**:
- `data/backtest/event_attempt.parquet`
- `data/parquet/intraday/1m/{SYMBOL}.parquet` (ë¶„ë´‰)

**í•µì‹¬ í”¼ì²˜ (80ê°œ = 20 Core Ã— 4 Windows)**:

##### A. ìœˆë„ìš° ì •ì˜

| ìœˆë„ìš° | íŒŒë¼ë¯¸í„° | ìš©ë„ |
|--------|----------|------|
| 15m | t_attempt - 15ë¶„ | ì§ì „ ëª¨ë©˜í…€ |
| 30m | t_attempt - 30ë¶„ | ë‹¨ê¸° ì¶”ì„¸ |
| 60m | t_attempt - 60ë¶„ | ì¤‘ê¸° íŒ¨í„´ |
| 120m | t_attempt - 120ë¶„ | ì¥ê¸° ì»¨í…ìŠ¤íŠ¸ |

##### B. í•µì‹¬ 20ê°œ ì§€í‘œ

| ì¹´í…Œê³ ë¦¬ | ì§€í‘œ | ì„¤ëª… |
|----------|------|------|
| **Momentum** | `ret_{w}m` | ìœˆë„ìš° ìˆ˜ìµë¥  |
| | `rsi_5` | RSI (5) |
| | `rsi_14` | RSI (14) |
| | `macd` | MACD |
| | `stoch_k` | Stochastic K |
| **Volume** | `vol_zscore_max` | ìµœëŒ€ ê±°ë˜ëŸ‰ z-score |
| | `vol_accel` | ê±°ë˜ëŸ‰ ê°€ì†ë„ |
| | `obv_change` | OBV ë³€í™” |
| | `cmf` | Chaikin Money Flow |
| | `spike_count` | RVOL ìŠ¤íŒŒì´í¬ íšŸìˆ˜ |
| **Volatility** | `range` | (high - low) / close |
| | `atr` | ATR |
| | `bb_width` | Bollinger í­ |
| | `bb_pos` | Bollinger ìœ„ì¹˜ |
| **Structure** | `vwap_dist` | (close - vwap) / vwap |
| | `above_vwap_ratio` | VWAP ìœ„ ë¹„ìœ¨ |
| | `pullback_depth` | ì§ì „ ëˆŒë¦¼ ê¹Šì´ |
| | `price_accel` | ê°€ê²© ê°€ì†ë„ |
| | `high_loc` | ê³ ì  ìœ„ì¹˜ (0~1) |
| | `close_loc` | ì¢…ê°€ ìœ„ì¹˜ (0~1) |

**t_attempt ì´ì „ë§Œ ì‚¬ìš© ê°•ì œ**:
```python
def build_attempt_features(symbol: str, trade_date: date, t_attempt: datetime) -> dict:
    """í¬ì¸íŠ¸-ì¸-íƒ€ì„ ê°•ì œ: t_attempt ì§ì „ê¹Œì§€ë§Œ ì‚¬ìš©"""
    minute_df = load_minute_bars(symbol, trade_date, before=t_attempt)
    
    features = {}
    for window in [15, 30, 60, 120]:
        window_df = minute_df.tail(window)
        features.update({
            f"ret_{window}m": calc_return(window_df),
            f"vol_zscore_max_{window}m": calc_vol_zscore_max(window_df),
            # ... ë‚˜ë¨¸ì§€ ì§€í‘œ
        })
    
    return features
```

**ì¶œë ¥**: `data/backtest/feat_intraday_at_attempt.parquet`

---

#### Step 3.2: Stage 1 í•™ìŠµ

**íŒŒì¼**: `scripts/backtest/train_stage1.py`

**ì…ë ¥**:
- `data/backtest/feat_intraday_at_attempt.parquet`
- `data/backtest/feat_d1_asof.parquet` (D-1 í”¼ì²˜ ì¼ë¶€)
- `data/backtest/label_attempt_outcome.parquet`

**ì²˜ë¦¬ ë¡œì§**:
```python
def train_stage1():
    # 1. ë°ì´í„° ë¡œë“œ
    attempt_features = pl.read_parquet("data/backtest/feat_intraday_at_attempt.parquet")
    d1_features = pl.read_parquet("data/backtest/feat_d1_asof.parquet")
    labels = pl.read_parquet("data/backtest/label_attempt_outcome.parquet")
    
    # 2. D-1 í”¼ì²˜ ì¼ë¶€ ì„ íƒ (ìƒìœ„ 10ê°œ)
    d1_top10 = ["atr_pctile", "tight_range_intensity", "dist_to_20d_low", ...]
    d1_subset = d1_features.select(["symbol", "trade_date"] + d1_top10)
    
    # 3. ë³‘í•©
    df = attempt_features.join(d1_subset, on=["symbol", "trade_date"])
    df = df.join(labels, on=["symbol", "trade_date", "attempt_id"])
    
    # 4. Positive/Negative ì •ì˜
    # Positive: is_success = True
    # Negative: is_failed_pump = True (í•˜ë“œ ë„¤ê±°í‹°ë¸Œ)
    df = df.filter(pl.col("is_success") | pl.col("is_failed_pump"))
    
    # 5. í•™ìŠµ (Stage 0ê³¼ ë™ì¼ êµ¬ì¡°)
    model = XGBClassifier(...)
    model.fit(X_train, y_train)
    
    return model
```

**ì¶œë ¥**:
- `data/backtest/model_stage1.joblib`
- `data/backtest/shap_stage1.png`

---

### Phase 4: í‰ê°€ ë° ê²€ì¦ (~4h)

#### Step 4.1: Recall@N í‰ê°€

**íŒŒì¼**: `scripts/backtest/evaluate_recall_at_n.py`

**ì²˜ë¦¬ ë¡œì§**:
```python
def evaluate_recall_at_n(model, df: pl.DataFrame, n: int = 200) -> dict:
    """
    ì¼ë³„ Recall@N í‰ê°€
    
    1. ê° trade_dateì— ëŒ€í•´:
       a. ëª¨ë“  ì¢…ëª©ì— ëŒ€í•´ ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚°
       b. ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ Nê°œ ì„ íƒ
       c. Top-N ì¤‘ ì‹¤ì œ Attempt ë¹„ìœ¨ (Recall)
    2. ì¼ë³„ Recall í‰ê·  ë° ë¶„í¬
    """
    results = []
    
    for trade_date in df["trade_date"].unique():
        day_df = df.filter(pl.col("trade_date") == trade_date)
        
        # ì˜ˆì¸¡ ì ìˆ˜
        scores = model.predict_proba(day_df[feature_cols])[:, 1]
        
        # Top-N
        top_n_idx = np.argsort(scores)[-n:]
        top_n_labels = day_df[top_n_idx]["has_attempt"].to_numpy()
        
        # ê·¸ë‚  ì‹¤ì œ Attempt ìˆ˜
        total_attempts = day_df["has_attempt"].sum()
        
        # Recall@N
        recall = top_n_labels.sum() / total_attempts if total_attempts > 0 else 0
        
        results.append({
            "trade_date": trade_date,
            "recall_at_n": recall,
            "total_attempts": total_attempts,
            "candidates": n
        })
    
    return pl.DataFrame(results)
```

**ì¶œë ¥ ì§€í‘œ**:

| ì§€í‘œ | Stage 0 | Stage 1 |
|------|---------|---------|
| Recall@200 (í‰ê· ) | â‰¥ 70% | N/A |
| Recall@200 (std) | ë³´ê³  | N/A |
| Candidates/day (í‰ê· ) | 150-250 | N/A |
| Alerts/day (í‰ê· ) | N/A | 20-50 |
| Success Rate | N/A | â‰¥ 50% |
| Lead Time (í‰ê· ) | N/A | â‰¥ 15min |

#### Step 4.2: ì—°ë„ë³„ ì•ˆì •ì„± í‰ê°€

```python
def evaluate_yearly_stability(model, df: pl.DataFrame) -> dict:
    """
    ì—°ë„ë³„ ì„±ëŠ¥ ë¶„ë¦¬ í‰ê°€
    - 2021 / 2022 / 2023 / 2024 / 2025
    - ìƒìœ„ í”¼ì²˜/ë£° ì¼ê´€ì„± í™•ì¸
    """
    years = [2021, 2022, 2023, 2024, 2025]
    results = {}
    
    for year in years:
        year_df = df.filter(pl.col("trade_date").dt.year() == year)
        metrics = evaluate_recall_at_n(model, year_df)
        results[year] = {
            "recall_at_200_mean": metrics["recall_at_n"].mean(),
            "recall_at_200_std": metrics["recall_at_n"].std(),
            "sample_count": len(year_df)
        }
    
    return results
```

---

## 8. ì˜ì¡´ì„± ìˆœì„œ

```mermaid
graph TD
    subgraph Phase1[Phase 1: ë°ì´í„° ì •ë¹„]
        A[1.1 í´ë” ìƒì„±] --> B[1.2 minute_volume_profile]
        B --> C[1.3 detect_attempt]
        C --> D[1.4 label_attempt_outcome]
    end
    
    subgraph Phase2[Phase 2: Stage 0]
        E[2.1 build_d1_features_v2]
        F[2.2 train_stage0]
        E --> F
    end
    
    subgraph Phase3[Phase 3: Stage 1]
        G[3.1 build_attempt_features]
        H[3.2 train_stage1]
        G --> H
    end
    
    subgraph Phase4[Phase 4: í‰ê°€]
        I[4.1 evaluate_recall_at_n]
        J[4.2 ì—°ë„ë³„ ì•ˆì •ì„±]
        I --> J
    end
    
    D --> E
    D --> G
    F --> I
    H --> I
```

**ë³‘ë ¬ ê°€ëŠ¥**:
- Phase 2ì™€ Phase 3ëŠ” Phase 1 ì™„ë£Œ í›„ ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥
- Step 2.1ê³¼ Step 3.1ì€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥

---

## 9. ê²€ì¦

### 9.1 ìë™ ê²€ì¦

```bash
# Lint
ruff check scripts/backtest/*.py

# Type check (ì„ íƒ)
mypy scripts/backtest/*.py

# ë°ì´í„° ë¬´ê²°ì„±
python scripts/backtest/validate_data.py
```

### 9.2 ìˆ˜ë™ ê²€ì¦

| ê²€ì¦ í•­ëª© | ë°©ë²• | ê¸°ëŒ€ ê²°ê³¼ |
|----------|------|----------|
| minute_volume_profile ì •í•©ì„± | ìƒ˜í”Œ 10ê°œ ìˆ˜ë™ ê²€ì‚° | 20ì¼ ì¤‘ì•™ê°’ ì¼ì¹˜ |
| Attempt íƒì§€ ì •í™•ë„ | control_groups.csv ëŒ€ë¹„ êµì°¨ ê²€ì¦ | Attempt ì¢…ëª© 100% íƒì§€ |
| asof_date ê°•ì œ | feat_d1_asofì— D-0 ë°ì´í„° ì—†ìŒ í™•ì¸ | asof_date < trade_date |
| í”¼ì²˜ ëˆ„ìˆ˜ ê²€ì‚¬ | t_attempt ì´í›„ ë°ì´í„° ë¯¸ì‚¬ìš© í™•ì¸ | ë¡œê·¸ ê²€ì¦ |

### 9.3 ì„±ê³¼ ê¸°ì¤€ (Pass/Fail)

| ì§€í‘œ | ê¸°ì¤€ | Pass ì¡°ê±´ |
|------|------|----------|
| Stage 0 Recall@200 | â‰¥ 70% | 2025 í…ŒìŠ¤íŠ¸ì…‹ ê¸°ì¤€ |
| Stage 0 Candidates/day | 150-250 | í‰ê·  ë²”ìœ„ ë‚´ |
| Stage 1 Alerts/day | 20-50 | í‰ê·  ë²”ìœ„ ë‚´ |
| Stage 1 Success Rate | â‰¥ 50% | 2025 í…ŒìŠ¤íŠ¸ì…‹ ê¸°ì¤€ |
| ì—°ë„ë³„ í¸ì°¨ | std < 15% | 2021-2024 CV ê¸°ì¤€ |

---

## 10. ë¦¬ìŠ¤í¬ ë° ì™„í™”

| ë¦¬ìŠ¤í¬ | ì˜í–¥ | ì™„í™” ë°©ì•ˆ |
|--------|------|----------|
| ë¶„ë´‰ ë°ì´í„° ëˆ„ë½ | Attempt íƒì§€ ì‹¤íŒ¨ | minute_coverage_report.csv ê²€ì¦ í›„ ë‹¤ìš´ë¡œë“œ |
| pandas_ta CCI ì´ìƒì¹˜ | í”¼ì²˜ ì˜¤ì—¼ | CCI ê°œë³„ ê²€ì¦ + ì´ìƒì¹˜ í•„í„°ë§ |
| Point-in-time ìœ„ë°˜ | ë°±í…ŒìŠ¤íŠ¸ ê³¼ì í•© | asof_date ì»¬ëŸ¼ ê°•ì œ, ë¡œê·¸ ê²€ì¦ |
| í´ë˜ìŠ¤ ë¶ˆê· í˜• | ëª¨ë¸ í¸í–¥ | scale_pos_weight, ìƒ˜í”Œë§ ì¡°ì • |

---

## 11. ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `scripts/control_groups.csv` ì¡´ì¬ í™•ì¸ (4,205+ í–‰)
- [ ] `data/parquet/daily/all_daily.parquet` ì¡´ì¬ í™•ì¸
- [ ] `data/parquet/intraday/1m/` ë””ë ‰í† ë¦¬ ë¶„ë´‰ ë°ì´í„° í™•ì¸
- [ ] `minute_coverage_report.csv` ê²€ì¦ â†’ ëˆ„ë½ ë¶„ë´‰ ë‹¤ìš´ë¡œë“œ

---

**ë¬¸ì„œ ì´ë ¥**
| ë²„ì „ | ì¼ì | ë³€ê²½ ë‚´ìš© |
|------|------|----------|
| 1.0 | 2026-01-15 | ì´ˆì•ˆ (005-01 ê¸°ë°˜ Full Plan í™•ì¥) |
