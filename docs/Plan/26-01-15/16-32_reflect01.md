1) 가장 큰 구조적 문제: “두 개의 다른 제품”을 한 모델/한 데이터셋으로 풀고 있음

문서의 운영 컨텍스트는 사실상 제품이 2개입니다.

D-1 스캐너(장전/전일 기준): 다음 날 급등할 만한 후보를 100~200개로 줄이는 “리트리벌/랭킹” 문제

M-n 실시간 경보(장중): 후보군에서 “지금 막 터지기 직전”을 잡는 “타이밍/위험도(하자드)” 문제

그런데 현재 설계는 X(~260 features)에 D-1 + 프리마켓 + M-n을 한꺼번에 넣고 y=is_daygainer로 한 번에 학습합니다.

왜 이게 문제인가?

**D-1 단계에서 쓸 수 없는 정보(M-n)**가 들어가면, 모델은 그 신호에 크게 의존합니다.
→ 룰을 뽑아도 D-1 스캐너로는 재현이 안 되거나, 재현하면 성능이 급락합니다.

평가 지표도 “스캐너(Top-N)” 중심이어야 하는데, 현재는 일반 분류(Recall 등) 중심입니다.
→ “Recall 70%”가 나와도, 실제로는 하루에 2,000종목 중 Top 200에 들어오느냐가 본질입니다.

결론: D-1과 M-n은 **분리 모델(혹은 분리 목적함수/분리 데이터 생성)**가 맞습니다.

2) 라벨/샘플링에서 생길 수 있는 치명적인 누수와 비현실성
(A) Case-Control(매칭 대조군) 설계는 “학습”엔 유리하지만 “운영 성능 추정”엔 위험

현재 대조군은 “그냥 아무 음성”이 아니라 RVOL 스파이크가 있었던 하드 네거티브 위주입니다. 이건 연구적으로 좋은데, 다음이 따라옵니다.

운영에서는 (D-1 단계에서) RVOL 스파이크를 아직 모르거나, 훨씬 다양한 음성(지루한 종목 포함)이 들어옵니다.

따라서 지금 데이터로 얻은 Precision/Threshold는 실제 베이스레이트에서 깨질 확률이 큼.

특히 “스캐너 룰”은 하드 네거티브에서만 강한 룰이 되기 쉽고, 풀 유니버스에서는 FP 폭발 가능.

✅ 해결 방향:

학습은 하드 네거티브를 적극 쓰되,

평가는 반드시 ‘풀 유니버스(또는 실제 D-1 프리필터 유니버스)’에서 하루 단위 Top-N 기준으로 해야 합니다.

(B) T0 정의/정렬이 “학습 순간”을 왜곡할 가능성
1) Positive T0를 “전일 종가 대비 +6% 최초 돌파”로 잡을 때

“급등 직전”을 잡는 게 아니라, 이미 +6%는 오른 뒤를 앵커로 잡습니다.

그러면 M-n 피처(예: price_momentum)는 결국 “이미 오르는 중” 정보를 담게 되고,

모델이 “선행 신호”가 아니라 ‘이미 시작된 급등’을 재확인하는 쪽으로 수렴하기 쉽습니다.
→ Lead time이 목표인데, 라벨 설계가 lead time을 갉아먹습니다.

2) Control에서 T0가 없으면 HOD 시점 fallback

이건 ML적으로 특히 위험합니다.

HOD는 사후적으로만 아는 시점이라서, “음성 중 가장 좋아 보이는 순간”에 정렬됩니다.

그러면 모델은 “실시간에서 마주치는 음성 분포”가 아니라
‘음성의 최상단 순간’ 분포로 훈련됩니다.

결과: 실시간에선 FP/알림 타이밍이 엉키거나, 특정 지표에 과최적화됩니다.

✅ 해결 방향(중요):
M-n은 “T0 기준 샷 1개”가 아니라, 아래 중 하나로 바꾸는 게 안정적입니다.

(추천) 하자드/타임스텝 데이터셋:
“t 시점까지 봤을 때, 남은 장중에 daygainer로 갈 확률”을 매 분(또는 5분) 학습

또는 “트리거 기반 샘플링”:
실제로 알림을 울릴 법한 이벤트(예: 첫 RVOL spike, 첫 VWAP 돌파, 첫 변동성 확장) 시점만 데이터로 만들고, 그 시점 이후 성공/실패로 라벨

3) 검증(Validation) 설계에서 가장 흔한 누수 포인트 3개
(A) “동일 날짜 매칭”을 했는데, CV split이 날짜를 쪼개면 누수

현재 대조군이 동일 날짜로 매칭되어 있죠. 그런데 TimeSeriesSplit을 “레코드 단위”로 하면,

같은 날짜의 샘플이 train/valid에 동시에 존재할 수 있고,

그날의 시장 환경/섹터 모멘텀/갭 분위기 같은 신호를 모델이 “암기”할 수 있습니다.

✅ 해결:

split은 반드시 group = trade_date 단위로 해야 합니다.

더 나아가 M-n까지 있으면 **purge/embargo(인접 구간 누수 방지)**를 두는 게 안전합니다.

(B) 롤링 피처(20D low 등) “전체 데이터로 먼저 계산”하면 누수

피처를 미리 전체 기간에 대해 계산해놓고 split하면,
롤링 통계가 미세하게나마 미래 정보를 섞을 위험이 큽니다(특히 결측 처리/정렬/리샘플에서).

✅ 해결:

“포인트-인-타임(point-in-time) 피처 스토어” 방식으로
각 fold에서 과거 데이터만으로 피처를 생성하는 파이프라인을 갖추는 게 이상적입니다.

(C) 동일 티커 반복 출현(특히 마이크로캡)로 인한 “티커 누수”

같은 티커가 여러 번 pump 이벤트를 만들면, 모델이 “패턴”이 아니라 “그 티커의 습성”을 배울 수 있습니다.

✅ 해결:

최소한 리포팅에서 Group by ticker 일반화 테스트(“본 적 없는 티커에서 성능”)를 한 번은 보세요.

운영이 “티커 재발견”이어도, 이 리포트가 있어야 과적합을 감지할 수 있습니다.

4) 해석 가능한 룰 추출 계획의 현실적 리스크

현재 계획: SHAP → 상위 K 피처 threshold → surrogate tree → 룰

이 방식은 흔하지만, 룰이 ‘그럴듯’해 보이고도 실전에서 잘 깨지는 패턴이 있습니다.

SHAP 상위 피처가 연도/레짐이 바뀌면 바뀜

surrogate tree는 본 모델의 결정을 근사할 뿐, 스캐너의 목표(Top-N/Alert budget)를 직접 최적화하지 않음

결과 룰이 “설명”은 되는데 “운영 KPI(일일 후보수/리콜)”를 못 맞춤

✅ 대안(룰이 최종 산출물이라면 특히 추천):

애초에 룰을 직접 학습하는 모델을 고려하세요.

RuleFit(룰+선형 결합)

Bayesian Rule Lists / CORELS(결정 리스트/룰셋 최적화)

Explainable Boosting Machine(EBM) + 간단한 interaction만 허용

또는 목표를 “Recall@N(일일 Top-N)”로 두고 룰을 탐색하는 방식(제약 최적화/그리디 탐색)

5) 새로운 대안 설계: “2단계 + (선택) 3단계”로 재정의

아래는 지금 문서의 의도를 최대한 살리면서, ML적으로 덜 위험하게 만드는 설계입니다.

대안 A: 2단계(스캐너 랭커 + 실시간 하자드 알림)
Stage 1) D-1(또는 프리마켓) 스캐너 = “하루 단위 랭킹 문제”
목표를 이렇게 바꿉니다

입력: (D-1 close까지) 일봉/메타 + (가능하면 D 프리마켓 초반까지) 프리마켓 피처

출력: 각 거래일마다 Top N(예: 200) 후보

목표함수/평가:

Recall@N (per day) : 그날 발생한 daygainer가 Top N에 들어왔는가

Candidates/day : 평균 후보수(=운영 비용)

(부가) day 단위 MRR / NDCG 같은 랭킹 지표

데이터셋 생성 방식(핵심)

지금처럼 case-control만 쓰지 말고, 최소한 평가 단계에서는:

각 거래일 D에 대해,

유니버스(혹은 운영에서 실제로 보는 프리필터 유니버스) 전체 종목에 대해

피처는 D-1 시점 정보만 사용

라벨은 “D에 daygainer가 되었는가”

학습 효율 때문에 음성은 다운샘플링하더라도, 검증/테스트는 풀 유니버스 분포로 합니다.

모델 후보

LightGBM/XGBoost의 ranking objective(LambdaRank/LambdaMART)
→ “Top 200 안에 넣기”에 최적

또는 classification + 일별 점수로 sorting (단, 목적함수는 랭킹이 더 정직)

룰 산출

랭커의 상위 피처/컷을 바탕으로

“일일 후보수 제한”을 만족하는 룰을 직접 탐색(그리디/ILP/룰학습)

Stage 2) M-n 실시간 경보 = “타임스텝/하자드(시간-의존) 문제”
핵심: “T0 한 점”을 버리고, “시간 흐름”으로 학습

각 종목-일에 대해 분봉을 흘려보면서:

매 시점 t에서 입력 X(t): 최근 15/30/60/120분 윈도우 피처

라벨 y(t): “장 마감 전까지 daygainer로 끝날 것인가(혹은 이후 K분 내 폭발할 것인가)”

이렇게 하면 HOD fallback 같은 비현실이 줄고,

“언제 알림을 울려야 하는지”를 직접 최적화할 수 있습니다.

운영과 더 맞는 학습 타깃 2가지(추천)

EOD 타깃: “오늘 끝까지 daygainer가 될 확률”

K분 타깃: “향후 30분 내 +X% 추가 상승(또는 변동성 확장)이 올 확률”
→ 이게 리드타임/타이밍에 더 직접적입니다.

알림 정책까지 함께 설계

알림은 “확률 > θ”가 아니라,

하루 알림 예산(예: 30회/day) 또는 종목당 1회 같은 제약과 함께 설계해야 FP 폭발을 막습니다.

대안 B(강추): 3단계 = “Pump Attempt”를 중간 타깃으로 분해

문서에 이미 “Failed Pump” 라벨을 따로 만들고 있죠. 이건 엄청 좋은 힌트입니다.

Stage 0) “내일/오늘 Pump Attempt가 생길 종목인가?”

(정의 예시) intraday RVOL spike + 일정 수준의 range 확장

이건 daygainer보다 훨씬 빈도가 높아 학습이 안정적입니다.

Stage 1) “Attempt 중에 성공(daygainer) vs 실패(failed pump)”

이때부터 M-n 타이밍 모델이 힘을 발휘합니다.

여기서야말로 “가격은 오르는데 볼륨이 받쳐주나”, “변동성 수축 후 확장” 같은 패턴이 의미를 갖습니다.

이 3단계로 가면:

D-1은 “Attempt 후보”를 잘 뽑는 데 집중(리콜)

M-n은 “성공/실패”를 가르는 데 집중(정밀도/타이밍)

룰도 “Attempt 룰”과 “Success 룰”로 분리되어 훨씬 해석 가능합니다.

6) 지금 설계에서 “우선순위 높게” 검증해야 할 실험 체크리스트

아래는 가치 대비 비용이 큰 실험 순서입니다.

1) 날짜 그룹 split 누수 체크(가장 먼저)

group = trade_date로 train/valid가 같은 날짜를 공유하지 않게 분할

기존 점수와 차이가 크면, 지금까지의 수치(Recall 70% 등)는 신뢰도 하락

2) “D-1 only 모델” vs “M-n 포함 모델” 성능 분리

D-1 스캐너가 진짜 목표라면, D-1만으로도 어느 정도 recall@200이 나와야 합니다.

M-n이 없으면 성능이 거의 0에 가까우면 → 지금 모델은 사실상 “이미 오른 걸 맞히는 모델”일 확률

3) 평가를 “일 단위 Top-N”으로 바꾸기

전체 recall/precision이 아니라,

**“하루에 N개 뽑았을 때 daygainer 커버율”**로 리포트

4) Control의 HOD fallback 제거/대체

음성 샘플 시점을 “랜덤 시간(분포 매칭)” 또는 “첫 spike 이벤트 시점” 등으로 재구성

성능이 흔들리면, 기존 방식은 운영 비정합 가능성이 큼

5) 룰 안정성(부트스트랩/연도별 안정성)

2021/2022/2023/2024/2025로 나눠서

상위 룰/피처가 얼마나 일관적인지 확인
→ 룰이 매년 바뀌면 “스캐너 룰”로 쓰기 어렵습니다.

7) (현 설계 유지 시) 최소 수정으로 리스크 크게 줄이는 “응급처치” 5개

완전히 갈아엎기 어렵다면, 이것만은 강력 추천합니다.

D-1 스캐너 모델을 별도로 학습 (피처도 D-1 + 프리마켓까지만)

CV를 trade_date 그룹 기준으로 바꾸기

피처 생성 파이프라인을 **fold 내부에서 생성(포인트-인-타임)**으로 바꾸기

M-n 데이터는 T0/HOD 한 점이 아니라 **여러 시점 샷(예: 10:00/11:00/12:00/13:00/14:00)**으로 만들기

최종 KPI를 Recall이 아니라 Recall@N(일일) + “알림 예산” 기반으로 재정의

8) 요약: 이 설계를 “좋은 연구”에서 “쓸 수 있는 제품”으로 만드는 핵심 전환

지금 설계의 가장 큰 위험은 목표(스캐너/알림)와 데이터/라벨/검증이 어긋난 상태로, 숫자만 좋아지는 방향으로 갈 수 있다는 점입니다.

해결책의 핵심은 단순합니다.

D-1 = 랭킹/리트리벌(Top-N)

M-n = 시간-의존 하자드(알림 예산 포함)

평가는 실제 운영 시뮬레이션(일 단위/알림 단위)